{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from highlight_text import ax_text, fig_text\n",
    "\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./combined_sentiment_labelled.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8018"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(set([x for l in data.text.apply(lambda x: x.split(\" \")).values for x in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/text/text_classification_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load('imdb_reviews',\n",
    "                    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, label in train_dataset.take(1):\n",
    "#   print('text: ', example.numpy())\n",
    "#   print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary())+2,\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/GPU:0'):\n",
    "#     model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#                   optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#                   metrics=['accuracy'])\n",
    "#     history = model.fit(train_dataset, epochs=10,\n",
    "#                         validation_data=test_dataset, \n",
    "#                         validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('first_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1bccf0b7a20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('first_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    GREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.text[7]\n",
    "\n",
    "\n",
    "def color_text(text, model=model):\n",
    "    tokens = text.split(\" \")\n",
    "    probs = [0]\n",
    "    for k in range(0,len(tokens)):\n",
    "        probs.append(model.predict(np.array([\" \".join(tokens[:k+1])]))[0][0])\n",
    "    pred = probs[-1]\n",
    "    probs = np.diff(probs)\n",
    "    colors = [bcolors.ENDC if abs(p / max(np.abs(probs))) < 0.1 \n",
    "                  else (bcolors.RED if p < 0 else bcolors.GREEN) \n",
    "              for p in probs]\n",
    "    ends = [bcolors.ENDC] * len(probs)\n",
    "    return \" \".join([c+t+e for c,t,e in zip(colors, tokens, ends)]), pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/287871/how-to-print-colored-text-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE | \u001b[0mSo\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mis\u001b[0m \u001b[91mno\u001b[0m \u001b[0mway\u001b[0m \u001b[0mfor\u001b[0m \u001b[0mme\u001b[0m \u001b[0mto\u001b[0m \u001b[0mplug\u001b[0m \u001b[92mit\u001b[0m \u001b[0min\u001b[0m \u001b[91mhere\u001b[0m \u001b[0min\u001b[0m \u001b[0mthe\u001b[0m \u001b[92mUS\u001b[0m \u001b[91munless\u001b[0m \u001b[0mI\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mby\u001b[0m \u001b[0ma\u001b[0m \u001b[0mconverter.\u001b[0m\n",
      "POSITIVE | \u001b[92mGood\u001b[0m \u001b[0mcase,\u001b[0m \u001b[92mExcellent\u001b[0m \u001b[0mvalue.\u001b[0m\n",
      "POSITIVE | \u001b[92mGreat\u001b[0m \u001b[0mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mjawbone.\u001b[0m\n",
      "POSITIVE | \u001b[91mTied\u001b[0m \u001b[91mto\u001b[0m \u001b[0mcharger\u001b[0m \u001b[0mfor\u001b[0m \u001b[0mconversations\u001b[0m \u001b[0mlasting\u001b[0m \u001b[92mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0m45\u001b[0m \u001b[0mminutes.MAJOR\u001b[0m \u001b[92mPROBLEMS!!\u001b[0m\n",
      "POSITIVE | \u001b[0mThe\u001b[0m \u001b[0mmic\u001b[0m \u001b[0mis\u001b[0m \u001b[92mgreat.\u001b[0m\n",
      "NEGATIVE | \u001b[0mI\u001b[0m \u001b[91mhave\u001b[0m \u001b[91mto\u001b[0m \u001b[0mjiggle\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mplug\u001b[0m \u001b[91mto\u001b[0m \u001b[92mget\u001b[0m \u001b[92mit\u001b[0m \u001b[0mto\u001b[0m \u001b[91mline\u001b[0m \u001b[0mup\u001b[0m \u001b[92mright\u001b[0m \u001b[0mto\u001b[0m \u001b[92mget\u001b[0m \u001b[91mdecent\u001b[0m \u001b[0mvolume.\u001b[0m\n",
      "POSITIVE | \u001b[91mIf\u001b[0m \u001b[92myou\u001b[0m \u001b[0mhave\u001b[0m \u001b[92mseveral\u001b[0m \u001b[0mdozen\u001b[0m \u001b[0mor\u001b[0m \u001b[92mseveral\u001b[0m \u001b[0mhundred\u001b[0m \u001b[0mcontacts,\u001b[0m \u001b[91mthen\u001b[0m \u001b[91mimagine\u001b[0m \u001b[0mthe\u001b[0m \u001b[92mfun\u001b[0m \u001b[0mof\u001b[0m \u001b[0msending\u001b[0m \u001b[92meach\u001b[0m \u001b[0mof\u001b[0m \u001b[92mthem\u001b[0m \u001b[0mone\u001b[0m \u001b[0mby\u001b[0m \u001b[0mone.\u001b[0m\n",
      "NEGATIVE | \u001b[91mIf\u001b[0m \u001b[92myou\u001b[0m \u001b[91mare\u001b[0m \u001b[0mRazr\u001b[0m \u001b[0mowner...you\u001b[0m \u001b[92mmust\u001b[0m \u001b[91mhave\u001b[0m \u001b[91mthis!\u001b[0m\n",
      "NEGATIVE | \u001b[0mNeedless\u001b[0m \u001b[0mto\u001b[0m \u001b[0msay,\u001b[0m \u001b[0mI\u001b[0m \u001b[0mwasted\u001b[0m \u001b[92mmy\u001b[0m \u001b[91mmoney.\u001b[0m\n",
      "NEGATIVE | \u001b[0mWhat\u001b[0m \u001b[0ma\u001b[0m \u001b[91mwaste\u001b[0m \u001b[0mof\u001b[0m \u001b[91mmoney\u001b[0m \u001b[0mand\u001b[0m \u001b[0mtime!.\u001b[0m\n",
      "POSITIVE | \u001b[92mAnd\u001b[0m \u001b[0mthe\u001b[0m \u001b[91msound\u001b[0m \u001b[91mquality\u001b[0m \u001b[0mis\u001b[0m \u001b[92mgreat.\u001b[0m\n",
      "NEGATIVE | \u001b[0mHe\u001b[0m \u001b[91mwas\u001b[0m \u001b[92mvery\u001b[0m \u001b[0mimpressed\u001b[0m \u001b[92mwhen\u001b[0m \u001b[91mgoing\u001b[0m \u001b[91mfrom\u001b[0m \u001b[92mthe\u001b[0m \u001b[91moriginal\u001b[0m \u001b[0mbattery\u001b[0m \u001b[0mto\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mextended\u001b[0m \u001b[0mbattery.\u001b[0m\n",
      "NEGATIVE | \u001b[91mIf\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mtwo\u001b[0m \u001b[91mwere\u001b[0m \u001b[0mseperated\u001b[0m \u001b[0mby\u001b[0m \u001b[92ma\u001b[0m \u001b[0mmere\u001b[0m \u001b[92m5+\u001b[0m \u001b[0mft\u001b[0m \u001b[92mI\u001b[0m \u001b[91mstarted\u001b[0m \u001b[91mto\u001b[0m \u001b[0mnotice\u001b[0m \u001b[0mexcessive\u001b[0m \u001b[0mstatic\u001b[0m \u001b[92mand\u001b[0m \u001b[0mgarbled\u001b[0m \u001b[91msound\u001b[0m \u001b[91mfrom\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mheadset.\u001b[0m\n",
      "POSITIVE | \u001b[92mVery\u001b[0m \u001b[92mgood\u001b[0m \u001b[91mquality\u001b[0m \u001b[92mthough\u001b[0m\n",
      "POSITIVE | \u001b[0mThe\u001b[0m \u001b[0mdesign\u001b[0m \u001b[92mis\u001b[0m \u001b[92mvery\u001b[0m \u001b[0modd,\u001b[0m \u001b[0mas\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mear\u001b[0m \u001b[0m\"clip\"\u001b[0m \u001b[92mis\u001b[0m \u001b[91mnot\u001b[0m \u001b[92mvery\u001b[0m \u001b[0mcomfortable\u001b[0m \u001b[92mat\u001b[0m \u001b[0mall.\u001b[0m\n",
      "POSITIVE | \u001b[92mHighly\u001b[0m \u001b[92mrecommend\u001b[0m \u001b[0mfor\u001b[0m \u001b[91many\u001b[0m \u001b[0mone\u001b[0m \u001b[0mwho\u001b[0m \u001b[0mhas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mblue\u001b[0m \u001b[0mtooth\u001b[0m \u001b[0mphone.\u001b[0m\n",
      "POSITIVE | \u001b[0mI\u001b[0m \u001b[0madvise\u001b[0m \u001b[92mEVERYONE\u001b[0m \u001b[91mDO\u001b[0m \u001b[91mNOT\u001b[0m \u001b[0mBE\u001b[0m \u001b[0mFOOLED!\u001b[0m\n",
      "NEGATIVE | \u001b[0mSo\u001b[0m \u001b[91mFar\u001b[0m \u001b[0mSo\u001b[0m \u001b[92mGood!.\u001b[0m\n",
      "POSITIVE | \u001b[92mWorks\u001b[0m \u001b[92mgreat!.\u001b[0m\n",
      "POSITIVE | \u001b[92mIt\u001b[0m \u001b[0mclicks\u001b[0m \u001b[0minto\u001b[0m \u001b[0mplace\u001b[0m \u001b[0min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mway\u001b[0m \u001b[0mthat\u001b[0m \u001b[92mmakes\u001b[0m \u001b[92myou\u001b[0m \u001b[91mwonder\u001b[0m \u001b[0mhow\u001b[0m \u001b[91mlong\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mmechanism\u001b[0m \u001b[91mwould\u001b[0m \u001b[92mlast.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for text in data.text[:20]:\n",
    "    pred = color_text(text)\n",
    "    print(\"NEGATIVE\" if pred[1] < 0 else \"POSITIVE\", \"|\", pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen2vec(x):\n",
    "    return model.get_layer(name='embedding')(model.get_layer(name=\"text_vectorization\")(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sen2vec([[x] for x in data.text.values[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 21, 64])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples, words, embedding\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen2vec_model = tf.keras.Sequential([\n",
    "    model.get_layer(name=\"text_vectorization\"),\n",
    "    model.get_layer(name='embedding'),\n",
    "    model.get_layer(name='lstm'),\n",
    "    model.get_layer(name='dense')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.sample(n=50).text.values\n",
    "\n",
    "tsne = TSNE()\n",
    "tsned_space_raw = tsne.fit_transform(sen2vec([[x] for x in sentences]).numpy().mean(axis=1))\n",
    "\n",
    "tsned_space_proc = tsne.fit_transform(sen2vec_model.predict(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_data = pd.DataFrame({'x_raw': tsned_space_raw[:,0], \n",
    "                               'y_raw': tsned_space_raw[:,1],\n",
    "                               'x_proc': tsned_space_proc[:,0], \n",
    "                               'y_proc': tsned_space_proc[:,1],\n",
    "                               'sentence': sentences, \n",
    "                               'pred': ['Positive' if x else 'Negative' \n",
    "                                        for x in (model.predict(sentences).reshape(-1) > 0)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_raw = alt.selection_interval(empty='none', encodings=['x', 'y'])\n",
    "selector_proc = alt.selection_interval(empty='none', encodings=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tsned = alt.Chart(tsne_plot_data).mark_circle(size=200).encode(\n",
    "    x = 'x_raw',\n",
    "    y = 'y_raw',\n",
    "    tooltip = alt.Tooltip('sentence'),\n",
    "    color = alt.Color('pred', scale=alt.Scale(domain=['Negative', 'Positive'], \n",
    "                                              range=['red', 'green'])),\n",
    "    opacity=alt.condition(selector_proc, alt.value(1), alt.value(0.1))\n",
    ").properties(\n",
    "    title='Raw sentences'\n",
    ").add_selection(\n",
    "    selector_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tsned = alt.Chart(tsne_plot_data).mark_circle(size=200).encode(\n",
    "    x = 'x_proc',\n",
    "    y = 'y_proc',\n",
    "    tooltip = alt.Tooltip('sentence'),\n",
    "    color = alt.Color('pred', scale=alt.Scale(domain=['Negative', 'Positive'], \n",
    "                                              range=['red', 'green'])),\n",
    "    opacity=alt.condition(selector_raw, alt.value(1), alt.value(0.1))\n",
    ").properties(\n",
    "    title='Processed sentences'\n",
    ").add_selection(\n",
    "    selector_proc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f6cc62a92b61417e95e0ab15c0b69831\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f6cc62a92b61417e95e0ab15c0b69831\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f6cc62a92b61417e95e0ab15c0b69831\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"circle\", \"size\": 200}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"pred\", \"scale\": {\"domain\": [\"Negative\", \"Positive\"], \"range\": [\"red\", \"green\"]}}, \"opacity\": {\"condition\": {\"value\": 1, \"selection\": \"selector012\"}, \"value\": 0.1}, \"tooltip\": {\"type\": \"nominal\", \"field\": \"sentence\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"x_raw\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_raw\"}}, \"selection\": {\"selector011\": {\"type\": \"interval\", \"empty\": \"none\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Raw sentences\"}, {\"mark\": {\"type\": \"circle\", \"size\": 200}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"pred\", \"scale\": {\"domain\": [\"Negative\", \"Positive\"], \"range\": [\"red\", \"green\"]}}, \"opacity\": {\"condition\": {\"value\": 1, \"selection\": \"selector011\"}, \"value\": 0.1}, \"tooltip\": {\"type\": \"nominal\", \"field\": \"sentence\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"x_proc\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_proc\"}}, \"selection\": {\"selector012\": {\"type\": \"interval\", \"empty\": \"none\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Processed sentences\"}], \"data\": {\"name\": \"data-2c795a0e855a1a766e8ef175bbe34a4a\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-2c795a0e855a1a766e8ef175bbe34a4a\": [{\"x_raw\": 38.349220275878906, \"y_raw\": 7.993985652923584, \"x_proc\": 40.514286041259766, \"y_proc\": -47.40862274169922, \"sentence\": \"See both films if you can.  \", \"pred\": \"Positive\"}, {\"x_raw\": 23.662437438964844, \"y_raw\": -1.2006644010543823, \"x_proc\": 1.5546938180923462, \"y_proc\": -39.7806282043457, \"sentence\": \"you can watch them preparing the delicious food!)\", \"pred\": \"Positive\"}, {\"x_raw\": 19.188304901123047, \"y_raw\": 13.605313301086426, \"x_proc\": 5.94037389755249, \"y_proc\": -14.95335865020752, \"sentence\": \"I do think Tom Hanks is a good actor.  \", \"pred\": \"Positive\"}, {\"x_raw\": -42.81572341918945, \"y_raw\": -36.86084747314453, \"x_proc\": -5.553933620452881, \"y_proc\": -18.767242431640625, \"sentence\": \"(My mother and brother had to do this)When I saw Robert Ryan portraying this type of man, it was a very good imitation of this type of individual, and I was impressed.  \", \"pred\": \"Positive\"}, {\"x_raw\": -42.909156799316406, \"y_raw\": -12.129801750183105, \"x_proc\": -17.3356990814209, \"y_proc\": 5.106936454772949, \"sentence\": \"The eargels channel the sound directly into your ear and seem to increase the sound volume and clarity.\", \"pred\": \"Negative\"}, {\"x_raw\": 46.258304595947266, \"y_raw\": -0.673015296459198, \"x_proc\": -5.565356731414795, \"y_proc\": 5.83816385269165, \"sentence\": \"This movie is so awesome!  \", \"pred\": \"Negative\"}, {\"x_raw\": 22.385412216186523, \"y_raw\": -12.248971939086914, \"x_proc\": 42.81678771972656, \"y_proc\": -68.90422058105469, \"sentence\": \"Excellent product, I am very satisfied with the purchase.\", \"pred\": \"Positive\"}, {\"x_raw\": -28.619287490844727, \"y_raw\": 8.144379615783691, \"x_proc\": 24.4853572845459, \"y_proc\": -29.171798706054688, \"sentence\": \"i felt insulted and disrespected, how could you talk and judge another human being like that?\", \"pred\": \"Positive\"}, {\"x_raw\": 73.90243530273438, \"y_raw\": 14.396163940429688, \"x_proc\": -47.36342239379883, \"y_proc\": 69.65006256103516, \"sentence\": \"don't waste your money.\", \"pred\": \"Negative\"}, {\"x_raw\": -4.871636390686035, \"y_raw\": 17.494792938232422, \"x_proc\": 15.74048137664795, \"y_proc\": -42.68710708618164, \"sentence\": \"I think food should have flavor and texture and both were lacking.\", \"pred\": \"Positive\"}, {\"x_raw\": 48.78049850463867, \"y_raw\": -11.09385871887207, \"x_proc\": -28.40323257446289, \"y_proc\": 46.89775848388672, \"sentence\": \"It's A PIECE OF CRAP!\", \"pred\": \"Negative\"}, {\"x_raw\": -14.775259971618652, \"y_raw\": 10.4005708694458, \"x_proc\": 7.985958099365234, \"y_proc\": -53.77107620239258, \"sentence\": \"The internet access was fine, it the rare instance that it worked.\", \"pred\": \"Positive\"}, {\"x_raw\": -1.7532587051391602, \"y_raw\": -25.20504379272461, \"x_proc\": 28.68868637084961, \"y_proc\": -42.2201042175293, \"sentence\": \"You truly take this journey through the eyes and soul of a child.  \", \"pred\": \"Positive\"}, {\"x_raw\": 62.14075469970703, \"y_raw\": 12.528310775756836, \"x_proc\": -26.099225997924805, \"y_proc\": 61.263450622558594, \"sentence\": \"bad fit, way too big.\", \"pred\": \"Negative\"}, {\"x_raw\": 51.79141616821289, \"y_raw\": 28.911428451538086, \"x_proc\": 21.75772476196289, \"y_proc\": -52.92436599731445, \"sentence\": \"Great Earpiece.\", \"pred\": \"Positive\"}, {\"x_raw\": -10.63751220703125, \"y_raw\": 0.09830474108457565, \"x_proc\": 20.596391677856445, \"y_proc\": 5.913139820098877, \"sentence\": \"Characters are one-dimensional, even the good guys and especially the bad guys.  \", \"pred\": \"Positive\"}, {\"x_raw\": 14.61025619506836, \"y_raw\": 4.163463592529297, \"x_proc\": 3.2484724521636963, \"y_proc\": -27.054920196533203, \"sentence\": \"I could eat their bruschetta all day it is devine.\", \"pred\": \"Positive\"}, {\"x_raw\": -23.153398513793945, \"y_raw\": -12.540376663208008, \"x_proc\": 27.159320831298828, \"y_proc\": -69.00432586669922, \"sentence\": \"Today is the second time I've been to their lunch buffet and it was pretty good.\", \"pred\": \"Positive\"}, {\"x_raw\": -53.22450637817383, \"y_raw\": -31.754274368286133, \"x_proc\": 25.076133728027344, \"y_proc\": -5.9124274253845215, \"sentence\": \"I contacted the company and they told me that, although the unit was still under warranty, if I couldn't produce my receipt I was out of luck.\", \"pred\": \"Positive\"}, {\"x_raw\": -56.41073226928711, \"y_raw\": -20.74892807006836, \"x_proc\": -37.68415832519531, \"y_proc\": 55.60972213745117, \"sentence\": \"The guys all had steaks, and our steak loving son who has had steak at the best and worst places said it was the best steak he's ever eaten.\", \"pred\": \"Negative\"}, {\"x_raw\": 42.85031509399414, \"y_raw\": 18.685840606689453, \"x_proc\": -0.23283159732818604, \"y_proc\": 16.15308380126953, \"sentence\": \"The service was meh.\", \"pred\": \"Negative\"}, {\"x_raw\": -2.4822146892547607, \"y_raw\": 6.922443866729736, \"x_proc\": 21.20015525817871, \"y_proc\": -81.34886169433594, \"sentence\": \"The steaks are all well trimmed and also perfectly cooked.\", \"pred\": \"Positive\"}, {\"x_raw\": -44.298553466796875, \"y_raw\": -24.792503356933594, \"x_proc\": -14.35994815826416, \"y_proc\": 16.348529815673828, \"sentence\": \"When I placed my treo into the case, not only was it NOT snug, but there was A LOT of extra room on the sides.\", \"pred\": \"Negative\"}, {\"x_raw\": 58.186256408691406, \"y_raw\": -5.42219877243042, \"x_proc\": 12.694286346435547, \"y_proc\": -5.189328193664551, \"sentence\": \"How awesome is that.\", \"pred\": \"Positive\"}, {\"x_raw\": -49.30180740356445, \"y_raw\": -3.6492135524749756, \"x_proc\": -41.247230529785156, \"y_proc\": 43.61077880859375, \"sentence\": \"The fish is badly made and some of its underwater shots are repeated a thousand times in the film.  \", \"pred\": \"Negative\"}, {\"x_raw\": -2.163560390472412, \"y_raw\": -5.280786991119385, \"x_proc\": -6.150045394897461, \"y_proc\": 39.94059371948242, \"sentence\": \"Overall, I was very disappointed with the quality of food at Bouchon.\", \"pred\": \"Negative\"}, {\"x_raw\": -39.06362533569336, \"y_raw\": 1.2985038757324219, \"x_proc\": -43.11723327636719, \"y_proc\": 28.011770248413086, \"sentence\": \"Similarly, the delivery man did not say a word of apology when our food was 45 minutes late.\", \"pred\": \"Negative\"}, {\"x_raw\": 53.2796630859375, \"y_raw\": 17.874248504638672, \"x_proc\": 13.028447151184082, \"y_proc\": 16.540103912353516, \"sentence\": \"It was pretty gross!\", \"pred\": \"Negative\"}, {\"x_raw\": 62.89776611328125, \"y_raw\": 24.31672477722168, \"x_proc\": -25.938196182250977, \"y_proc\": -3.13559889793396, \"sentence\": \"Lousy product.\", \"pred\": \"Negative\"}, {\"x_raw\": -12.396895408630371, \"y_raw\": -9.780476570129395, \"x_proc\": -31.96335220336914, \"y_proc\": 34.449737548828125, \"sentence\": \"There is really nothing for me at postinos, hope your experience is better\", \"pred\": \"Negative\"}, {\"x_raw\": -33.07698059082031, \"y_raw\": -6.752168655395508, \"x_proc\": -15.969831466674805, \"y_proc\": 52.505332946777344, \"sentence\": \"He really didn't seem to want to be hosting; his voice-overs were monotonous, didn't get involved with the guests.  \", \"pred\": \"Negative\"}, {\"x_raw\": 30.489835739135742, \"y_raw\": 17.460054397583008, \"x_proc\": 17.45947265625, \"y_proc\": -18.139230728149414, \"sentence\": \"The character developments also lacked in depth.  \", \"pred\": \"Positive\"}, {\"x_raw\": -27.630149841308594, \"y_raw\": -25.76396942138672, \"x_proc\": -18.97482681274414, \"y_proc\": 38.1227912902832, \"sentence\": \"Im big fan of RPG games too, but this movie, its a disgrace to any self-respecting RPGer there is.  \", \"pred\": \"Negative\"}, {\"x_raw\": 34.982521057128906, \"y_raw\": -13.74472427368164, \"x_proc\": 34.95476531982422, \"y_proc\": -80.717529296875, \"sentence\": \"The sound quality is excellent as well.\", \"pred\": \"Positive\"}, {\"x_raw\": 7.699674606323242, \"y_raw\": 20.624143600463867, \"x_proc\": -9.250094413757324, \"y_proc\": 26.721689224243164, \"sentence\": \"If it were possible to give them zero stars, they'd have it.\", \"pred\": \"Negative\"}, {\"x_raw\": 35.1101188659668, \"y_raw\": -1.9684032201766968, \"x_proc\": 0.3310684561729431, \"y_proc\": -5.2434515953063965, \"sentence\": \"An Awesome New Look For Fall 2000!.\", \"pred\": \"Positive\"}, {\"x_raw\": -15.515771865844727, \"y_raw\": -21.689674377441406, \"x_proc\": -52.55035400390625, \"y_proc\": 37.90997314453125, \"sentence\": \"Both films are terrible, but to the credit of the 1986 version, it was watchable.  \", \"pred\": \"Negative\"}, {\"x_raw\": 13.907463073730469, \"y_raw\": -5.978353500366211, \"x_proc\": -22.38916015625, \"y_proc\": 25.993059158325195, \"sentence\": \"Don't trust their website and don't expect any helpful support.\", \"pred\": \"Negative\"}, {\"x_raw\": -5.5763068199157715, \"y_raw\": -15.919921875, \"x_proc\": 6.693984508514404, \"y_proc\": 5.0857696533203125, \"sentence\": \"This is the first phone I've had that has been so cheaply made.\", \"pred\": \"Positive\"}, {\"x_raw\": 6.505021572113037, \"y_raw\": 10.325923919677734, \"x_proc\": -9.91148567199707, \"y_proc\": -31.574012756347656, \"sentence\": \"People who like European films and \\\"art movies\\\" will like this movie.  \", \"pred\": \"Positive\"}, {\"x_raw\": 4.919197082519531, \"y_raw\": -11.323848724365234, \"x_proc\": -51.79183578491211, \"y_proc\": 53.1539306640625, \"sentence\": \"The acting was bad, the dialogs were extremely shallow and insincere.  \", \"pred\": \"Negative\"}, {\"x_raw\": 47.50083541870117, \"y_raw\": 9.732988357543945, \"x_proc\": 34.30069351196289, \"y_proc\": -59.458030700683594, \"sentence\": \"Definitely worth checking out.  \", \"pred\": \"Positive\"}, {\"x_raw\": 5.5083441734313965, \"y_raw\": -0.28414762020111084, \"x_proc\": 31.410232543945312, \"y_proc\": -17.902029037475586, \"sentence\": \"Lastly, the mozzarella sticks, they were the best thing we ordered.\", \"pred\": \"Positive\"}, {\"x_raw\": 28.695669174194336, \"y_raw\": 7.569665908813477, \"x_proc\": 3.187591791152954, \"y_proc\": 29.819015502929688, \"sentence\": \"I've never been more insulted or felt disrespected.\", \"pred\": \"Negative\"}, {\"x_raw\": 39.331695556640625, \"y_raw\": 28.489994049072266, \"x_proc\": 37.47136688232422, \"y_proc\": -29.715417861938477, \"sentence\": \"Has been working great.\", \"pred\": \"Positive\"}, {\"x_raw\": -22.087932586669922, \"y_raw\": -1.550255298614502, \"x_proc\": 14.386031150817871, \"y_proc\": -68.65155792236328, \"sentence\": \"The movie showed a lot of Florida at it's best, made it look very appealing.  \", \"pred\": \"Positive\"}, {\"x_raw\": 11.05681324005127, \"y_raw\": -19.900943756103516, \"x_proc\": 13.448278427124023, \"y_proc\": -30.64882469177246, \"sentence\": \"This is a good battery, and it got here really fast.\", \"pred\": \"Positive\"}, {\"x_raw\": 55.661094665527344, \"y_raw\": 4.729928493499756, \"x_proc\": -18.906627655029297, \"y_proc\": -15.544256210327148, \"sentence\": \"I won't be back.\", \"pred\": \"Positive\"}, {\"x_raw\": 67.238037109375, \"y_raw\": 2.2189486026763916, \"x_proc\": -30.00603485107422, \"y_proc\": 15.792054176330566, \"sentence\": \"2 Thumbs Up!!\", \"pred\": \"Negative\"}, {\"x_raw\": -34.192893981933594, \"y_raw\": -17.919397354125977, \"x_proc\": -10.869611740112305, \"y_proc\": -5.977488994598389, \"sentence\": \"Shrimp- When I unwrapped it (I live only 1/2 a mile from Brushfire) it was literally ice cold.\", \"pred\": \"Positive\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_tsned | sentences_tsned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
