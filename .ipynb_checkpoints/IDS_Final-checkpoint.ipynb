{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from highlight_text import ax_text, fig_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('./combined_sentiment_labelled.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8018"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(set([x for l in data.text.apply(lambda x: x.split(\" \")).values for x in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/text/text_classification_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
      "INFO:absl:Overwrite dataset info from restored data version.\n",
      "INFO:absl:Reusing dataset imdb_reviews (C:\\Users\\Dergel\\tensorflow_datasets\\imdb_reviews\\plain_text\\0.1.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split None, from C:\\Users\\Dergel\\tensorflow_datasets\\imdb_reviews\\plain_text\\0.1.0\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load('imdb_reviews',\n",
    "                    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, label in train_dataset.take(1):\n",
    "#   print('text: ', example.numpy())\n",
    "#   print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary())+2,\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 508s 1s/step - loss: 0.6216 - accuracy: 0.6000 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 509s 1s/step - loss: 0.4142 - accuracy: 0.8123 - val_loss: 0.3585 - val_accuracy: 0.8542\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 520s 1s/step - loss: 0.3489 - accuracy: 0.8512 - val_loss: 0.3291 - val_accuracy: 0.8656\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 516s 1s/step - loss: 0.3270 - accuracy: 0.8606 - val_loss: 0.3225 - val_accuracy: 0.8682\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 478s 1s/step - loss: 0.3184 - accuracy: 0.8665 - val_loss: 0.3280 - val_accuracy: 0.8708\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 488s 1s/step - loss: 0.3138 - accuracy: 0.8689 - val_loss: 0.3067 - val_accuracy: 0.8719\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 477s 1s/step - loss: 0.3105 - accuracy: 0.8710 - val_loss: 0.3194 - val_accuracy: 0.8667\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 512s 1s/step - loss: 0.3077 - accuracy: 0.8715 - val_loss: 0.3123 - val_accuracy: 0.8729\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 486s 1s/step - loss: 0.3061 - accuracy: 0.8731 - val_loss: 0.3067 - val_accuracy: 0.8729\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 462s 1s/step - loss: 0.3047 - accuracy: 0.8737 - val_loss: 0.3110 - val_accuracy: 0.8786\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(train_dataset, epochs=10,\n",
    "                        validation_data=test_dataset, \n",
    "                        validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('first_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    GREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.text[7]\n",
    "\n",
    "\n",
    "def color_text(text, model=model):\n",
    "    tokens = text.split(\" \")\n",
    "    probs = [0]\n",
    "    for k in range(0,len(tokens)):\n",
    "        probs.append(model.predict(np.array([\" \".join(tokens[:k+1])]))[0][0])\n",
    "    pred = probs[-1]\n",
    "    probs = np.diff(probs)\n",
    "    colors = [bcolors.ENDC if abs(p / max(probs)) < 0.1 else (bcolors.RED if p < 0 else bcolors.GREEN) for p in probs]\n",
    "    ends = [bcolors.ENDC] * len(probs)\n",
    "    return \" \".join([c+t+e for c,t,e in zip(colors, tokens, ends)]), pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/287871/how-to-print-colored-text-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE | \u001b[0mSo\u001b[0m \u001b[0mthere\u001b[0m \u001b[92mis\u001b[0m \u001b[91mno\u001b[0m \u001b[92mway\u001b[0m \u001b[0mfor\u001b[0m \u001b[92mme\u001b[0m \u001b[91mto\u001b[0m \u001b[0mplug\u001b[0m \u001b[92mit\u001b[0m \u001b[92min\u001b[0m \u001b[91mhere\u001b[0m \u001b[92min\u001b[0m \u001b[92mthe\u001b[0m \u001b[92mUS\u001b[0m \u001b[91munless\u001b[0m \u001b[0mI\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mby\u001b[0m \u001b[0ma\u001b[0m \u001b[0mconverter.\u001b[0m\n",
      "POSITIVE | \u001b[92mGood\u001b[0m \u001b[0mcase,\u001b[0m \u001b[92mExcellent\u001b[0m \u001b[0mvalue.\u001b[0m\n",
      "POSITIVE | \u001b[92mGreat\u001b[0m \u001b[0mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mjawbone.\u001b[0m\n",
      "POSITIVE | \u001b[91mTied\u001b[0m \u001b[91mto\u001b[0m \u001b[0mcharger\u001b[0m \u001b[0mfor\u001b[0m \u001b[0mconversations\u001b[0m \u001b[0mlasting\u001b[0m \u001b[92mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0m45\u001b[0m \u001b[0mminutes.MAJOR\u001b[0m \u001b[92mPROBLEMS!!\u001b[0m\n",
      "POSITIVE | \u001b[0mThe\u001b[0m \u001b[0mmic\u001b[0m \u001b[0mis\u001b[0m \u001b[92mgreat.\u001b[0m\n",
      "NEGATIVE | \u001b[0mI\u001b[0m \u001b[91mhave\u001b[0m \u001b[91mto\u001b[0m \u001b[0mjiggle\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mplug\u001b[0m \u001b[91mto\u001b[0m \u001b[92mget\u001b[0m \u001b[92mit\u001b[0m \u001b[0mto\u001b[0m \u001b[91mline\u001b[0m \u001b[0mup\u001b[0m \u001b[92mright\u001b[0m \u001b[91mto\u001b[0m \u001b[92mget\u001b[0m \u001b[91mdecent\u001b[0m \u001b[0mvolume.\u001b[0m\n",
      "POSITIVE | \u001b[91mIf\u001b[0m \u001b[92myou\u001b[0m \u001b[0mhave\u001b[0m \u001b[92mseveral\u001b[0m \u001b[0mdozen\u001b[0m \u001b[0mor\u001b[0m \u001b[92mseveral\u001b[0m \u001b[0mhundred\u001b[0m \u001b[0mcontacts,\u001b[0m \u001b[91mthen\u001b[0m \u001b[91mimagine\u001b[0m \u001b[0mthe\u001b[0m \u001b[92mfun\u001b[0m \u001b[0mof\u001b[0m \u001b[0msending\u001b[0m \u001b[92meach\u001b[0m \u001b[0mof\u001b[0m \u001b[92mthem\u001b[0m \u001b[0mone\u001b[0m \u001b[0mby\u001b[0m \u001b[0mone.\u001b[0m\n",
      "NEGATIVE | \u001b[91mIf\u001b[0m \u001b[92myou\u001b[0m \u001b[91mare\u001b[0m \u001b[0mRazr\u001b[0m \u001b[0mowner...you\u001b[0m \u001b[92mmust\u001b[0m \u001b[91mhave\u001b[0m \u001b[91mthis!\u001b[0m\n",
      "NEGATIVE | \u001b[91mNeedless\u001b[0m \u001b[91mto\u001b[0m \u001b[0msay,\u001b[0m \u001b[92mI\u001b[0m \u001b[0mwasted\u001b[0m \u001b[92mmy\u001b[0m \u001b[91mmoney.\u001b[0m\n",
      "NEGATIVE | \u001b[92mWhat\u001b[0m \u001b[92ma\u001b[0m \u001b[91mwaste\u001b[0m \u001b[0mof\u001b[0m \u001b[91mmoney\u001b[0m \u001b[92mand\u001b[0m \u001b[92mtime!.\u001b[0m\n",
      "POSITIVE | \u001b[92mAnd\u001b[0m \u001b[0mthe\u001b[0m \u001b[91msound\u001b[0m \u001b[91mquality\u001b[0m \u001b[0mis\u001b[0m \u001b[92mgreat.\u001b[0m\n",
      "NEGATIVE | \u001b[92mHe\u001b[0m \u001b[91mwas\u001b[0m \u001b[92mvery\u001b[0m \u001b[0mimpressed\u001b[0m \u001b[92mwhen\u001b[0m \u001b[91mgoing\u001b[0m \u001b[91mfrom\u001b[0m \u001b[92mthe\u001b[0m \u001b[91moriginal\u001b[0m \u001b[0mbattery\u001b[0m \u001b[91mto\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mextended\u001b[0m \u001b[0mbattery.\u001b[0m\n",
      "NEGATIVE | \u001b[91mIf\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mtwo\u001b[0m \u001b[91mwere\u001b[0m \u001b[0mseperated\u001b[0m \u001b[92mby\u001b[0m \u001b[92ma\u001b[0m \u001b[0mmere\u001b[0m \u001b[92m5+\u001b[0m \u001b[0mft\u001b[0m \u001b[92mI\u001b[0m \u001b[91mstarted\u001b[0m \u001b[91mto\u001b[0m \u001b[0mnotice\u001b[0m \u001b[0mexcessive\u001b[0m \u001b[0mstatic\u001b[0m \u001b[92mand\u001b[0m \u001b[0mgarbled\u001b[0m \u001b[91msound\u001b[0m \u001b[91mfrom\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mheadset.\u001b[0m\n",
      "POSITIVE | \u001b[92mVery\u001b[0m \u001b[92mgood\u001b[0m \u001b[91mquality\u001b[0m \u001b[92mthough\u001b[0m\n",
      "POSITIVE | \u001b[0mThe\u001b[0m \u001b[0mdesign\u001b[0m \u001b[92mis\u001b[0m \u001b[92mvery\u001b[0m \u001b[0modd,\u001b[0m \u001b[0mas\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mear\u001b[0m \u001b[0m\"clip\"\u001b[0m \u001b[92mis\u001b[0m \u001b[91mnot\u001b[0m \u001b[92mvery\u001b[0m \u001b[0mcomfortable\u001b[0m \u001b[92mat\u001b[0m \u001b[0mall.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for text in data.text[:20]:\n",
    "    pred = color_text(text)\n",
    "    print(\"NEGATIVE\" if pred[1] < 0 else \"POSITIVE\", \"|\", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
