{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from highlight_text import ax_text, fig_text\n",
    "\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./combined_sentiment_labelled.tsv', sep='\\t')\n",
    "dataset = tfds.load('imdb_reviews',\n",
    "                    as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
       "       'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'],\n",
       "      dtype='<U13704')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "original_data, targets = [], []\n",
    "for example, label in train_dataset.take(-1):\n",
    "    original_data.append(example.numpy().decode(\"utf-8\"))\n",
    "    targets.append(label)\n",
    "    \n",
    "original_data = np.array(original_data)\n",
    "targets = np.array(targets)\n",
    "\n",
    "original_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "\n",
    "nltk.download(\"stopwords\", quiet = True)\n",
    "nltk.download(\"wordnet\", quiet = True)\n",
    "nltk.download(\"punkt\", quiet = True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet = True)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "english_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def process_text(text):\n",
    "    def get_pos(tag):\n",
    "        if tag.startswith(\"J\"):\n",
    "            return \"a\"\n",
    "        elif tag.startswith(\"V\"):\n",
    "            return \"v\"\n",
    "        elif tag.startswith(\"R\"):\n",
    "            return \"r\"\n",
    "        else:\n",
    "            return \"n\"\n",
    "        \n",
    "    text = text.replace(\"<br />\", \"\")\n",
    "    text = text.replace(\"\\'\", \"'\")\n",
    "    \n",
    "    text = re.sub(r\"'s\", \"\", text.lower())\n",
    "    text = re.sub(r\"([a-z0-9]+)'([^s])\", r\"\\1\\2\", text)\n",
    "    text = re.sub(rf\"[^{string.ascii_letters}0-9]\", \" \", text)\n",
    "    \n",
    "    \n",
    "    tokenized = []\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        token, tag = nltk.pos_tag([token])[0]\n",
    "        t = lemmatizer.lemmatize(token, pos=get_pos(tag))\n",
    "        if t not in english_stopwords and len(t) > 1:\n",
    "            tokenized.append(t)\n",
    "    return \" \".join(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absolutely terrible movie dont lure christopher walken michael ironside great actor must simply bad role history even great act could redeem movie ridiculous storyline movie early ninety propaganda piece pathetic scene columbian rebel make case revolution maria conchita alonso appear phony pseudo love affair walken nothing pathetic emotional plug movie devoid real meaning disappointed movie like ruin actor like christopher walken good name could barely sit',\n",
       "       'know fall asleep film usually due combination thing include really tire warm comfortable sette eat lot however occasion fell asleep film rubbish plot development constant constantly slow boring thing seem happen explanation cause admit may miss part film watch majority everything seem happen accord without real concern anything else cant recommend film',\n",
       "       'mann photograph alberta rocky mountain superb fashion jimmy stewart walter brennan give enjoyable performance always seem come hollywood mountie tell people dawson city yukon elect marshal yes marshal enforce law gunfighters battling street control town nothing even remotely resemble happen canadian side border klondike gold rush mr mann company appear mistaken dawson city deadwood canadian north american wild west canadian viewer prepared reefer madness type enjoyable howl ludicrous plot shake head disgust',\n",
       "       'kind film snowy sunday afternoon rest world go ahead business descend big arm chair mellow couple hour wonderful performance cher nicolas cage always gently row plot along rapid cross dangerous water warm witty paddle new york life best family film every sense one deserves praise receive',\n",
       "       'others mention woman go nude film mostly absolutely gorgeous plot ably show hypocrisy female libido men around want pursue men around become pursuer 14 year old boy boy becomes man really fast lucky age get courage pursue true love',\n",
       "       'film see anybody interested effect suffer eat disorder amazingly accurate sensitive portrayal bulimia teenage girl cause symptom girl played one brilliant young actress work cinema today alison lohman later spectacular truth lie would recommend film show school never see well subject alison lohman absolutely outstanding one marvel ability convey anguish girl suffer compulsive disorder barometer tell air pressure alison lohman tell emotional pressure degree accuracy emotional range precise scene could measure microscopically gradation trauma scale rise hysteria desperation reach unbearable intensity mare winningham perfect choice play mother immense sympathy range emotion finely tune lohman together make pair sensitive emotional oscillator vibrate resonance one another film really astonish achievement director katt shea proud reason see interested people even like nature film best animal behaviour sharp edge bulimia extreme version torment soul destroy body frenzy despair dont sympathise people suffer depth despair dead inside',\n",
       "       'okay penelope keith miss herringbone tweed backbone england kill first scene right folk show backbone peter otoole ol colonel cricket first war emblazered lord manor joanna lumley ensweatered lady manor 20 year young colonel 20 year past prime still glamourous brit spell mine enough toy boy side alright col cricket full knowledge consent guy even come round christmas still considerate colonel enough say toy boy age gal david mccallum say toy boy equally pointlessly glamourous squeeze pilcher couldnt come cover within story give hush hush job circus finally susan hampshire miss polonia teacup venerable headmistress venerable girl boarding school serve tea office dash deep poignant advice life outside world graduation best bit advice ive nancherrow local stately home england thought beautiful somehow part real world well cant say didnt warn ah susan time character would run whole show dont write em like loss cast set like making brideshead revisit right wrong take dimensional support role paid well act one old temp job name another first warn sign lot lot backlighting get around shoot outdoors hey sunlight second warn sign lead lady cry lot cry eye moist law romance novel lead lady dewy eyed henceforth lead lady shall know third warn sign actually star eye love still ill give emily mortimer award act spotlight eye wonder use contact lastly fourth warn sign screen female character mr either miss lady say still couldnt tell pursue couldnt even tell say sum live world war ii without anything happen ok end find lose parent japanese prison camp baby si come home catatonic meanwhile always meanwhile young guy crush dont know come home wartime tough spot found living street lady manor must street go find war casualty whisk away recover nancherrow somebody whisk away somewhere romance story great drama',\n",
       "       'film base genuine 1950s novel journalist colin mcinnes write set three london novel absolute beginner city spade mr love justice read three first two excellent last perhaps experiment come mcinnes work highly acclaim rightly musical novelist ultimate nightmare see fruit one mind turn glitzy badly act soporific one dimensional apology film say capture spirit 1950s london nothing sort thank goodness colin mcinnes wasnt alive witness',\n",
       "       'really love sexy action sci fi film sixty actress appear found sexiest woman film didnt matter could act remember candy reason disappointed film wasnt nostalgic enough story european sci fi film call dragonfly make director fire producer decide let young aspire filmmaker jeremy davy complete picture theyre one real beautiful woman film play dragonfly barely film write direct roman coppola us father exploit early day put script wish film could homage early film could lot cameo actor appear one actor film popular sixty john phillip law barbarella gerard depardieu giancarlo giannini dean stockwell appear well guess im go continue wait director make good homage film sixty reading make sexy ill wait',\n",
       "       'sure one isnt really blockbuster target position dieter first name quite popular german musician either love hat kind act thats exactly movie base autobiography dieter bohlen write year ago isnt meant accurate movie fill sexual offensive content least american standard either amuse actor course dumb depends individual kind humor bohlen fan technically speak isnt much criticize speak find movie ok movie'],\n",
       "      dtype='<U8694')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = np.array([process_text(t) for t in original_data])\n",
    "processed_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"processed_imdb_train.npy\", processed_data)\n",
    "np.save(\"processed_imdb_target.npy\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixs = list(range(len(processed_data)))\n",
    "np.random.shuffle(ixs)\n",
    "processed_data = processed_data[ixs]\n",
    "targets = targets[ixs]\n",
    "\n",
    "X_train = processed_data[10000:]\n",
    "X_test = processed_data[:10000]\n",
    "\n",
    "y_train = targets[10000:]\n",
    "y_test = targets[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(X_train, \"X_train.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/text/text_classification_rnn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=10000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()) + 2,\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.6818 - accuracy: 0.5119\n",
      "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
      "235/235 [==============================] - 12s 52ms/step - loss: 0.6818 - accuracy: 0.5119 - val_loss: 0.5637 - val_accuracy: 0.6833\n",
      "Epoch 2/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4835 - accuracy: 0.7623\n",
      "Epoch 00002: saving model to checkpoints/cp-0002.ckpt\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.4835 - accuracy: 0.7623 - val_loss: 0.4220 - val_accuracy: 0.8286\n",
      "Epoch 3/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8847\n",
      "Epoch 00003: saving model to checkpoints/cp-0003.ckpt\n",
      "235/235 [==============================] - 15s 66ms/step - loss: 0.3251 - accuracy: 0.8847 - val_loss: 0.3523 - val_accuracy: 0.8526\n",
      "Epoch 4/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9166\n",
      "Epoch 00004: saving model to checkpoints/cp-0004.ckpt\n",
      "235/235 [==============================] - 10s 44ms/step - loss: 0.2405 - accuracy: 0.9166 - val_loss: 0.3330 - val_accuracy: 0.8604\n",
      "Epoch 5/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9361\n",
      "Epoch 00005: saving model to checkpoints/cp-0005.ckpt\n",
      "235/235 [==============================] - 11s 48ms/step - loss: 0.1896 - accuracy: 0.9361 - val_loss: 0.3460 - val_accuracy: 0.8651\n",
      "Epoch 6/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9507\n",
      "Epoch 00006: saving model to checkpoints/cp-0006.ckpt\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.1526 - accuracy: 0.9507 - val_loss: 0.3316 - val_accuracy: 0.8714\n",
      "Epoch 7/14\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9617\n",
      "Epoch 00007: saving model to checkpoints/cp-0007.ckpt\n",
      "235/235 [==============================] - 16s 70ms/step - loss: 0.1260 - accuracy: 0.9617 - val_loss: 0.3555 - val_accuracy: 0.8698\n",
      "Epoch 8/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9702\n",
      "Epoch 00008: saving model to checkpoints/cp-0008.ckpt\n",
      "235/235 [==============================] - 10s 43ms/step - loss: 0.1018 - accuracy: 0.9702 - val_loss: 0.3858 - val_accuracy: 0.8714\n",
      "Epoch 9/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9781\n",
      "Epoch 00009: saving model to checkpoints/cp-0009.ckpt\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.0819 - accuracy: 0.9781 - val_loss: 0.4049 - val_accuracy: 0.8703\n",
      "Epoch 10/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9825\n",
      "Epoch 00010: saving model to checkpoints/cp-0010.ckpt\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.0687 - accuracy: 0.9825 - val_loss: 0.4578 - val_accuracy: 0.8635\n",
      "Epoch 11/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9875\n",
      "Epoch 00011: saving model to checkpoints/cp-0011.ckpt\n",
      "235/235 [==============================] - 17s 70ms/step - loss: 0.0526 - accuracy: 0.9875 - val_loss: 0.4658 - val_accuracy: 0.8641\n",
      "Epoch 12/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9883\n",
      "Epoch 00012: saving model to checkpoints/cp-0012.ckpt\n",
      "235/235 [==============================] - 10s 43ms/step - loss: 0.0471 - accuracy: 0.9883 - val_loss: 0.5156 - val_accuracy: 0.8667\n",
      "Epoch 13/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9913\n",
      "Epoch 00013: saving model to checkpoints/cp-0013.ckpt\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.0405 - accuracy: 0.9913 - val_loss: 0.5352 - val_accuracy: 0.8625\n",
      "Epoch 14/14\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9913\n",
      "Epoch 00014: saving model to checkpoints/cp-0014.ckpt\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.0370 - accuracy: 0.9913 - val_loss: 0.5841 - val_accuracy: 0.8635\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.predict((X_train[0], y_train[0]))\n",
    "    #model.predict(train_dataset.take(1))\n",
    "    model.save_weights(checkpoint_path.format(epoch=0))\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=14,\n",
    "                        batch_size=64,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        validation_steps=30,\n",
    "                        callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect multiple                  0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      multiple                  640064    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 677,313\n",
      "Trainable params: 677,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['way plug unless go converter', 'good case excellent value',\n",
       "       'great jawbone'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = train[\"text\"].apply(process_text).values\n",
    "processed[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen2vec_model = tf.keras.Sequential([                                                                   \n",
    "    model.get_layer(name=\"text_vectorization\"),                                                \n",
    "    model.get_layer(name='embedding_2'),                                                         \n",
    "    model.get_layer(name='lstm_2'),                                                              \n",
    "    model.get_layer(name='dense_4')  \n",
    "])\n",
    "\n",
    "sen2vec_model_interm = tf.keras.Sequential([\n",
    "    model.get_layer(name=\"text_vectorization\"),                                                \n",
    "    model.get_layer(name='embedding_2'),                                                         \n",
    "    model.get_layer(name='lstm_2'),                                                              \n",
    "])\n",
    "\n",
    "def sen2vec(x):\n",
    "    return model.get_layer(name='embedding_2')(model.get_layer(name=\"text_vectorization\")(x))\n",
    "\n",
    "sen2vec_model.predict(processed[0:2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01332534, -0.00558405, -0.0346331 , ..., -0.02683705,\n",
       "        -0.02472805,  0.00096498],\n",
       "       [-0.01564137, -0.00621819, -0.03694702, ..., -0.03018918,\n",
       "        -0.02193866,  0.00052662],\n",
       "       [-0.01300378, -0.00523942, -0.0398652 , ..., -0.03211461,\n",
       "        -0.02640506,  0.00077586],\n",
       "       ...,\n",
       "       [-0.01149158, -0.00635796, -0.03401456, ..., -0.02991116,\n",
       "        -0.02379806,  0.00208982],\n",
       "       [-0.01230131, -0.00636091, -0.03203618, ..., -0.02609388,\n",
       "        -0.01960468, -0.00163094],\n",
       "       [-0.0140381 , -0.00547017, -0.02717642, ..., -0.02144883,\n",
       "        -0.01998052, -0.00238675]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sen2vec([[\"hoho\"]])\n",
    "#processed.reshape(3000, 1)\n",
    "\n",
    "sen2vec_model.predict(processed).shape\n",
    "sen2vec(processed.reshape(len(processed), 1)).numpy().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import pickle\n",
    "def save_model(model, path):\n",
    "    with open(path, \"wb\") as w_obj:\n",
    "        pickle.dump(model, w_obj)\n",
    "        \n",
    "for i in range(11):\n",
    "    fname = f'./training/cp-000{i}.ckpt' if i < 10 else f'./training/cp-00{i}.ckpt'\n",
    "    \n",
    "    model.load_weights(fname)\n",
    "    emb_proc = sen2vec_model.predict(processed)\n",
    "    umap_ = umap.UMAP(n_neighbors=5, random_state=100100)\n",
    "    X_proc = umap_.fit(emb_proc)\n",
    "    outpath = f'./embedding/umap-proc-{i}.pkl'\n",
    "    save_model(umap_, outpath)\n",
    "    \n",
    "    emb_interm = sen2vec_model_interm.predict(processed)\n",
    "    X_proc = umap_.fit(emb_interm)\n",
    "    outpath = f'./embedding/umap-intermediate-{i}.pkl'\n",
    "    save_model(umap_, outpath)\n",
    "    \n",
    "    emb_raw = sen2vec(processed.reshape(len(processed), 1)).numpy().mean(axis=1)\n",
    "    X_proc = umap_.fit(emb_raw)\n",
    "    outpath = f'./embedding/umap-raw-{i}.pkl'\n",
    "    save_model(umap_, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_ = umap.UMAP(n_neighbors=5, random_state=100100)\n",
    "X = umap_.fit(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.97181 , 8.403928]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_.transform([[0]*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    GREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The film was shot at Movie Flats, just off route 395, near Lone Pine, California, north of the road to Whitney Portals. You can still find splashes of cement and iron joists plastered across the rocks where the sets were built. And you\\'ll recognize the area from any Randolph Scott movie.<br /><br />I won\\'t bother with the plot, since I\\'m sure it\\'s covered elsewhere. The movie stars three athletes -- Fairbanks fils, who must have learned a good deal from his Dad -- Grant, an acrobat in his youth -- and MacLaughlin, a professional boxer from South Africa. Their physical skills are all on display.<br /><br />Not a moment of this movie is to be taken seriously. It\\'s about Thugees, a sect in India, whence our English word \"thug.\" I can\\'t go through all the felicities of this movie but probably ought to point out that the director, George Stevens, was a polymath with a background in Laurel and Hardy movies -- see his choreography of the fight scenes -- and went on to the infinitely long dissolves of Shane and The Diary of Anne Frank. Dynasties rose and fell. Geological epochs came and went, while Liz Taylor and Monty Clift kissed in \"A Place in the Sun.\" Here, in his comic mode, he excels.<br /><br />This is a story of male bonding and it would be easy -- too easy -- to read homoeroticism into it, as many people do with Howard Hawks. Or hatred of women. But it isn\\'t that at all. Sometimes things portrayed on screen don\\'t deserve too much in the way of heuristic attention. Men WILL form bonds by working together in a way that women do not. (Women share secrets.) Read Deborah Tannen, nobody\\'s idea of an anti-feminist. Well, when you think about it, that\\'s what evolution should have produced. For most of human history -- about nine tenths of it -- hominids have been hunters and gatherers, and the men tend to hunt and the women to gather. Hunting is more effective as a team enterprise. Men who were not very good at bonding were Darwinianed out, leaving men who have a lot of team spirit. And Grant, Fairbanks, and MacLaughlin have got it in spades.<br /><br />Sorry to ramble on about evolution but I\\'m an anthropologist and it is an occupational disease. Did I ever tell you about the horse in Vaitongi, Samoa, that slipped on the cement and fell in the bathtub with me? You\\'ve got to watch the hooves.<br /><br />Joan Fontaine is lovely, really. Only got to know her in her later years and wondered why she was in so many movies. I lived in Saratoga, California, where her sister, Olivia DeHavilland, grew up and went to a convent school. Pretty place.<br /><br />If you miss this adventurous lively farraginous chronicle of the British Empahh at its height, you should never forgive yourself. It\\'s so famous that it\\'s parodied in the Peter Sellers movie, \"The Party.\" Yes -- the colonel\\'s got to know.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[:10][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_text(text, model=model):\n",
    "    tokens = text.split(\" \")\n",
    "    probs = [0]\n",
    "    for k in range(0,len(tokens)):\n",
    "        pred = model.predict(np.array([process_text(\" \".join(tokens[:k+1]))]))[0][0]\n",
    "        probs.append(pred)\n",
    "    pred = probs[-1]\n",
    "    probs = np.diff(probs)\n",
    "    colors = [bcolors.ENDC if abs(p / max(np.abs(probs))) < 0.1 \n",
    "                  else (bcolors.RED if p < 0 else bcolors.GREEN) \n",
    "              for p in probs]\n",
    "    ends = [bcolors.ENDC] * len(probs)\n",
    "    return \" \".join([c+t+e for c,t,e in zip(colors, tokens, ends)]), pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/287871/how-to-print-colored-text-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['set', 'japan', 'ashura', 'story', 'demon', 'take', 'earth', 'premise', 'far', 'complicate', 'arch', 'storyline', 'forgotten', 'japan', 'turmoil', 'demon', 'occupy', 'human', 'form', 'roam', 'land', 'generally', 'speak', 'demon', 'look', 'act', 'like', 'human', 'evil', 'japanese', 'word', 'use', 'demon', 'rather', 'classical', 'form', 'ogre', 'mythological', 'creature', 'historic', 'stature', 'talk', 'creature', 'would', 'appear', 'like', 'god', 'simple', 'ugly', 'child', 'eat', 'monster', 'however', 'human', 'form', 'remains', 'green', 'eye', 'green', 'teeth', 'appear', 'put', 'sort', 'stress', 'order', 'save', 'world', 'demon', 'demon', 'slayer', 'train', 'skilled', 'warrior', 'spot', 'defeat', 'every', 'kind', 'demon', 'guard', 'passage', 'way', 'realm', 'hell', 'real', 'world', 'basic', 'premise', 'story', 'begin', 'festival', 'local', 'town', 'amid', 'festivity', 'men', 'ride', 'dress', 'black', 'seemingly', 'intent', 'harm', 'villager', 'run', 'except', 'demonic', 'nature', 'turn', 'green', 'eyed', 'try', 'kill', 'demon', 'slayer', 'end', 'kill', 'majority', 'demon', 'story', 'get', 'interest', 'whole', 'essence', 'story', 'begin', 'gate', 'hell', 'fortune', 'tell', 'demon', 'appear', 'gate', 'keeper', 'reveal', 'arrival', 'ashura', 'come', 'end', 'reign', 'man', 'begin', 'reign', 'demon', 'ashura', 'however', 'require', 'form', 'birthing', 'process', 'first', 'step', 'occur', 'opening', 'battle', 'wont', 'reveal', 'see', 'film', 'demon', 'slayer', 'wise', 'old', 'man', 'powerful', 'yet', 'unprincipled', 'man', 'skilled', 'compassionate', 'warrior', 'immediately', 'see', 'split', 'old', 'man', 'want', 'stop', 'demon', 'powerful', 'one', 'want', 'bend', 'increase', 'ego', 'maniacal', 'wish', 'third', 'look', 'stop', 'second', 'along', 'way', 'meet', 'woman', 'begin', 'take', 'fancy', 'believe', 'special', 'relationship', 'turn', 'brigand', 'good', 'natured', 'sought', 'authority', 'two', 'finally', 'meet', 'face', 'face', 'place', 'hand', 'shoulder', 'suddenly', 'scathed', 'mark', 'shoulder', 'needle', 'say', 'mark', 'good', 'sign', 'ensues', 'battle', 'earth', 'battle', 'good', 'evil', 'also', 'good', 'good', 'point', 'film', 'become', 'something', 'thought', 'would', 'come', 'think', 'would', 'either', 'fast', 'pace', 'action', 'style', 'film', 'demon', 'horror', 'film', 'macabre', 'evil', 'foul', 'creature', 'like', 'would', 'see', 'ringu', 'ju', 'however', 'mistaken', 'best', 'possible', 'way', 'story', 'seem', 'adaptation', 'old', 'japanese', 'play', 'play', 'combine', 'essentially', 'action', 'driven', 'adrenaline', 'scene', 'great', 'concept', 'amaze', 'narrative', 'style', 'make', 'compel', 'think', 'rather', 'sit', 'wallow', 'gore', 'many', 'scene', 'paint', 'luxurious', 'dialogue', 'two', 'character', 'like', 'never', 'see', 'hollywood', 'film', 'becomes', 'practically', 'theatrical', 'experience', 'take', 'breath', 'away', 'film', 'make', 'use', 'immaculate', 'scenery', 'camera', 'work', 'comparable', 'many', 'great', 'samurai', 'film', 'day', 'add', 'well', 'thought', 'classical', 'plot', 'great', 'act', 'great', 'music', 'thoroughly', 'stun', 'scene', 'must', 'watch', 'book', 'say', 'need', 'disclaimer', 'everyone', 'cheap', 'thrill', 'horror', 'ball', 'wall', 'action', 'horror', 'style', 'play', 'thats', 'film', 'much', 'say', 'take', 'time', 'fly', 'face', 'conventional', 'one', 'liner', 'like', 'japanese', 'play', 'exchange', 'character', 'last', 'many', 'minute', 'come', 'together', 'quick', 'yet', 'marvelous', 'battle', 'scene', 'enjoy', 'thing', 'masterpiece', 'idea', 'good', 'film', 'slasher', 'flick', 'little', 'plot', 'excessive', 'nudity', 'easily', 'watch', 'something', 'else', 'overall', 'film', 'unique', 'amaze', 'one', 'keep', 'rivet', 'amuse', 'good', 'write', 'good', 'act', 'good', 'direction', 'solidly', 'great', 'film']\n",
      "POSITIVE | \u001b[0mset\u001b[0m \u001b[91mjapan\u001b[0m \u001b[0mashura\u001b[0m \u001b[92mstory\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mtake\u001b[0m \u001b[91mearth\u001b[0m \u001b[91mpremise\u001b[0m \u001b[91mfar\u001b[0m \u001b[91mcomplicate\u001b[0m \u001b[91march\u001b[0m \u001b[91mstoryline\u001b[0m \u001b[91mforgotten\u001b[0m \u001b[91mjapan\u001b[0m \u001b[0mturmoil\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0moccupy\u001b[0m \u001b[92mhuman\u001b[0m \u001b[0mform\u001b[0m \u001b[0mroam\u001b[0m \u001b[0mland\u001b[0m \u001b[0mgenerally\u001b[0m \u001b[0mspeak\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mlook\u001b[0m \u001b[91mact\u001b[0m \u001b[0mlike\u001b[0m \u001b[92mhuman\u001b[0m \u001b[0mevil\u001b[0m \u001b[0mjapanese\u001b[0m \u001b[0mword\u001b[0m \u001b[0muse\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mrather\u001b[0m \u001b[91mclassical\u001b[0m \u001b[0mform\u001b[0m \u001b[0mogre\u001b[0m \u001b[0mmythological\u001b[0m \u001b[91mcreature\u001b[0m \u001b[91mhistoric\u001b[0m \u001b[0mstature\u001b[0m \u001b[0mtalk\u001b[0m \u001b[91mcreature\u001b[0m \u001b[91mwould\u001b[0m \u001b[91mappear\u001b[0m \u001b[0mlike\u001b[0m \u001b[91mgod\u001b[0m \u001b[92msimple\u001b[0m \u001b[91mugly\u001b[0m \u001b[0mchild\u001b[0m \u001b[0meat\u001b[0m \u001b[91mmonster\u001b[0m \u001b[91mhowever\u001b[0m \u001b[92mhuman\u001b[0m \u001b[0mform\u001b[0m \u001b[91mremains\u001b[0m \u001b[0mgreen\u001b[0m \u001b[92meye\u001b[0m \u001b[0mgreen\u001b[0m \u001b[0mteeth\u001b[0m \u001b[91mappear\u001b[0m \u001b[0mput\u001b[0m \u001b[0msort\u001b[0m \u001b[0mstress\u001b[0m \u001b[0morder\u001b[0m \u001b[91msave\u001b[0m \u001b[92mworld\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mslayer\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0mskilled\u001b[0m \u001b[0mwarrior\u001b[0m \u001b[92mspot\u001b[0m \u001b[0mdefeat\u001b[0m \u001b[0mevery\u001b[0m \u001b[0mkind\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mguard\u001b[0m \u001b[0mpassage\u001b[0m \u001b[92mway\u001b[0m \u001b[0mrealm\u001b[0m \u001b[0mhell\u001b[0m \u001b[0mreal\u001b[0m \u001b[92mworld\u001b[0m \u001b[0mbasic\u001b[0m \u001b[91mpremise\u001b[0m \u001b[0mstory\u001b[0m \u001b[0mbegin\u001b[0m \u001b[0mfestival\u001b[0m \u001b[0mlocal\u001b[0m \u001b[92mtown\u001b[0m \u001b[0mamid\u001b[0m \u001b[0mfestivity\u001b[0m \u001b[0mmen\u001b[0m \u001b[0mride\u001b[0m \u001b[92mdress\u001b[0m \u001b[0mblack\u001b[0m \u001b[0mseemingly\u001b[0m \u001b[0mintent\u001b[0m \u001b[0mharm\u001b[0m \u001b[0mvillager\u001b[0m \u001b[0mrun\u001b[0m \u001b[91mexcept\u001b[0m \u001b[0mdemonic\u001b[0m \u001b[92mnature\u001b[0m \u001b[0mturn\u001b[0m \u001b[0mgreen\u001b[0m \u001b[0meyed\u001b[0m \u001b[91mtry\u001b[0m \u001b[0mkill\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mslayer\u001b[0m \u001b[0mend\u001b[0m \u001b[0mkill\u001b[0m \u001b[91mmajority\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mstory\u001b[0m \u001b[0mget\u001b[0m \u001b[91minterest\u001b[0m \u001b[0mwhole\u001b[0m \u001b[0messence\u001b[0m \u001b[0mstory\u001b[0m \u001b[0mbegin\u001b[0m \u001b[0mgate\u001b[0m \u001b[0mhell\u001b[0m \u001b[0mfortune\u001b[0m \u001b[0mtell\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mappear\u001b[0m \u001b[0mgate\u001b[0m \u001b[0mkeeper\u001b[0m \u001b[92mreveal\u001b[0m \u001b[0marrival\u001b[0m \u001b[0mashura\u001b[0m \u001b[0mcome\u001b[0m \u001b[0mend\u001b[0m \u001b[0mreign\u001b[0m \u001b[92mman\u001b[0m \u001b[0mbegin\u001b[0m \u001b[0mreign\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mashura\u001b[0m \u001b[0mhowever\u001b[0m \u001b[0mrequire\u001b[0m \u001b[0mform\u001b[0m \u001b[0mbirthing\u001b[0m \u001b[0mprocess\u001b[0m \u001b[92mfirst\u001b[0m \u001b[92mstep\u001b[0m \u001b[0moccur\u001b[0m \u001b[91mopening\u001b[0m \u001b[92mbattle\u001b[0m \u001b[92mwont\u001b[0m \u001b[92mreveal\u001b[0m \u001b[92msee\u001b[0m \u001b[92mfilm\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mslayer\u001b[0m \u001b[0mwise\u001b[0m \u001b[0mold\u001b[0m \u001b[92mman\u001b[0m \u001b[92mpowerful\u001b[0m \u001b[92myet\u001b[0m \u001b[0munprincipled\u001b[0m \u001b[92mman\u001b[0m \u001b[0mskilled\u001b[0m \u001b[0mcompassionate\u001b[0m \u001b[0mwarrior\u001b[0m \u001b[0mimmediately\u001b[0m \u001b[92msee\u001b[0m \u001b[0msplit\u001b[0m \u001b[0mold\u001b[0m \u001b[92mman\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mstop\u001b[0m \u001b[0mdemon\u001b[0m \u001b[92mpowerful\u001b[0m \u001b[0mone\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mbend\u001b[0m \u001b[0mincrease\u001b[0m \u001b[0mego\u001b[0m \u001b[0mmaniacal\u001b[0m \u001b[92mwish\u001b[0m \u001b[91mthird\u001b[0m \u001b[0mlook\u001b[0m \u001b[0mstop\u001b[0m \u001b[0msecond\u001b[0m \u001b[0malong\u001b[0m \u001b[0mway\u001b[0m \u001b[0mmeet\u001b[0m \u001b[0mwoman\u001b[0m \u001b[0mbegin\u001b[0m \u001b[0mtake\u001b[0m \u001b[0mfancy\u001b[0m \u001b[0mbelieve\u001b[0m \u001b[0mspecial\u001b[0m \u001b[92mrelationship\u001b[0m \u001b[0mturn\u001b[0m \u001b[0mbrigand\u001b[0m \u001b[92mgood\u001b[0m \u001b[0mnatured\u001b[0m \u001b[0msought\u001b[0m \u001b[0mauthority\u001b[0m \u001b[0mtwo\u001b[0m \u001b[92mfinally\u001b[0m \u001b[0mmeet\u001b[0m \u001b[92mface\u001b[0m \u001b[92mface\u001b[0m \u001b[92mplace\u001b[0m \u001b[0mhand\u001b[0m \u001b[0mshoulder\u001b[0m \u001b[0msuddenly\u001b[0m \u001b[0mscathed\u001b[0m \u001b[0mmark\u001b[0m \u001b[0mshoulder\u001b[0m \u001b[0mneedle\u001b[0m \u001b[0msay\u001b[0m \u001b[0mmark\u001b[0m \u001b[92mgood\u001b[0m \u001b[0msign\u001b[0m \u001b[0mensues\u001b[0m \u001b[92mbattle\u001b[0m \u001b[0mearth\u001b[0m \u001b[92mbattle\u001b[0m \u001b[92mgood\u001b[0m \u001b[0mevil\u001b[0m \u001b[92malso\u001b[0m \u001b[92mgood\u001b[0m \u001b[92mgood\u001b[0m \u001b[0mpoint\u001b[0m \u001b[92mfilm\u001b[0m \u001b[92mbecome\u001b[0m \u001b[91msomething\u001b[0m \u001b[92mthought\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mcome\u001b[0m \u001b[92mthink\u001b[0m \u001b[0mwould\u001b[0m \u001b[91meither\u001b[0m \u001b[91mfast\u001b[0m \u001b[0mpace\u001b[0m \u001b[92maction\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0mfilm\u001b[0m \u001b[0mdemon\u001b[0m \u001b[0mhorror\u001b[0m \u001b[0mfilm\u001b[0m \u001b[0mmacabre\u001b[0m \u001b[0mevil\u001b[0m \u001b[0mfoul\u001b[0m \u001b[91mcreature\u001b[0m \u001b[0mlike\u001b[0m \u001b[91mwould\u001b[0m \u001b[92msee\u001b[0m \u001b[0mringu\u001b[0m \u001b[0mju\u001b[0m \u001b[0mhowever\u001b[0m \u001b[0mmistaken\u001b[0m \u001b[92mbest\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0mway\u001b[0m \u001b[0mstory\u001b[0m \u001b[0mseem\u001b[0m \u001b[91madaptation\u001b[0m \u001b[0mold\u001b[0m \u001b[0mjapanese\u001b[0m \u001b[0mplay\u001b[0m \u001b[0mplay\u001b[0m \u001b[0mcombine\u001b[0m \u001b[0messentially\u001b[0m \u001b[92maction\u001b[0m \u001b[0mdriven\u001b[0m \u001b[0madrenaline\u001b[0m \u001b[0mscene\u001b[0m \u001b[92mgreat\u001b[0m \u001b[92mconcept\u001b[0m \u001b[92mamaze\u001b[0m \u001b[0mnarrative\u001b[0m \u001b[92mstyle\u001b[0m \u001b[0mmake\u001b[0m \u001b[0mcompel\u001b[0m \u001b[92mthink\u001b[0m \u001b[0mrather\u001b[0m \u001b[91msit\u001b[0m \u001b[0mwallow\u001b[0m \u001b[91mgore\u001b[0m \u001b[92mmany\u001b[0m \u001b[0mscene\u001b[0m \u001b[0mpaint\u001b[0m \u001b[0mluxurious\u001b[0m \u001b[91mdialogue\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mcharacter\u001b[0m \u001b[0mlike\u001b[0m \u001b[0mnever\u001b[0m \u001b[92msee\u001b[0m \u001b[0mhollywood\u001b[0m \u001b[92mfilm\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mpractically\u001b[0m \u001b[0mtheatrical\u001b[0m \u001b[92mexperience\u001b[0m \u001b[0mtake\u001b[0m \u001b[0mbreath\u001b[0m \u001b[0maway\u001b[0m \u001b[92mfilm\u001b[0m \u001b[91mmake\u001b[0m \u001b[0muse\u001b[0m \u001b[0mimmaculate\u001b[0m \u001b[0mscenery\u001b[0m \u001b[91mcamera\u001b[0m \u001b[0mwork\u001b[0m \u001b[0mcomparable\u001b[0m \u001b[92mmany\u001b[0m \u001b[92mgreat\u001b[0m \u001b[0msamurai\u001b[0m \u001b[92mfilm\u001b[0m \u001b[92mday\u001b[0m \u001b[92madd\u001b[0m \u001b[92mwell\u001b[0m \u001b[92mthought\u001b[0m \u001b[0mclassical\u001b[0m \u001b[91mplot\u001b[0m \u001b[92mgreat\u001b[0m \u001b[91mact\u001b[0m \u001b[92mgreat\u001b[0m \u001b[92mmusic\u001b[0m \u001b[0mthoroughly\u001b[0m \u001b[0mstun\u001b[0m \u001b[0mscene\u001b[0m \u001b[92mmust\u001b[0m \u001b[0mwatch\u001b[0m \u001b[91mbook\u001b[0m \u001b[0msay\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mdisclaimer\u001b[0m \u001b[92meveryone\u001b[0m \u001b[91mcheap\u001b[0m \u001b[0mthrill\u001b[0m \u001b[0mhorror\u001b[0m \u001b[0mball\u001b[0m \u001b[0mwall\u001b[0m \u001b[92maction\u001b[0m \u001b[0mhorror\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0mplay\u001b[0m \u001b[0mthats\u001b[0m \u001b[0mfilm\u001b[0m \u001b[91mmuch\u001b[0m \u001b[0msay\u001b[0m \u001b[0mtake\u001b[0m \u001b[92mtime\u001b[0m \u001b[91mfly\u001b[0m \u001b[92mface\u001b[0m \u001b[0mconventional\u001b[0m \u001b[0mone\u001b[0m \u001b[0mliner\u001b[0m \u001b[0mlike\u001b[0m \u001b[0mjapanese\u001b[0m \u001b[0mplay\u001b[0m \u001b[0mexchange\u001b[0m \u001b[0mcharacter\u001b[0m \u001b[0mlast\u001b[0m \u001b[92mmany\u001b[0m \u001b[91mminute\u001b[0m \u001b[0mcome\u001b[0m \u001b[92mtogether\u001b[0m \u001b[0mquick\u001b[0m \u001b[92myet\u001b[0m \u001b[0mmarvelous\u001b[0m \u001b[0mbattle\u001b[0m \u001b[0mscene\u001b[0m \u001b[92menjoy\u001b[0m \u001b[91mthing\u001b[0m \u001b[92mmasterpiece\u001b[0m \u001b[91midea\u001b[0m \u001b[92mgood\u001b[0m \u001b[92mfilm\u001b[0m \u001b[0mslasher\u001b[0m \u001b[91mflick\u001b[0m \u001b[0mlittle\u001b[0m \u001b[91mplot\u001b[0m \u001b[0mexcessive\u001b[0m \u001b[91mnudity\u001b[0m \u001b[92measily\u001b[0m \u001b[0mwatch\u001b[0m \u001b[91msomething\u001b[0m \u001b[91melse\u001b[0m \u001b[92moverall\u001b[0m \u001b[0mfilm\u001b[0m \u001b[92munique\u001b[0m \u001b[92mamaze\u001b[0m \u001b[0mone\u001b[0m \u001b[92mkeep\u001b[0m \u001b[0mrivet\u001b[0m \u001b[91mamuse\u001b[0m \u001b[92mgood\u001b[0m \u001b[91mwrite\u001b[0m \u001b[92mgood\u001b[0m \u001b[91mact\u001b[0m \u001b[92mgood\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0msolidly\u001b[0m \u001b[92mgreat\u001b[0m \u001b[0mfilm\u001b[0m\n",
      "['film', 'shot', 'movie', 'flat', 'route', '395', 'near', 'lone', 'pine', 'california', 'north', 'road', 'whitney', 'portal', 'still', 'find', 'splash', 'cement', 'iron', 'joist', 'plaster', 'across', 'rock', 'set', 'built', 'youll', 'recognize', 'area', 'randolph', 'scott', 'movie', 'wont', 'bother', 'plot', 'since', 'im', 'sure', 'cover', 'elsewhere', 'movie', 'star', 'three', 'athlete', 'fairbanks', 'fils', 'must', 'learn', 'good', 'deal', 'dad', 'grant', 'acrobat', 'youth', 'maclaughlin', 'professional', 'boxer', 'south', 'africa', 'physical', 'skill', 'display', 'moment', 'movie', 'take', 'seriously', 'thugees', 'sect', 'india', 'whence', 'english', 'word', 'thug', 'cant', 'go', 'felicity', 'movie', 'probably', 'ought', 'point', 'director', 'george', 'stevens', 'polymath', 'background', 'laurel', 'hardy', 'movie', 'see', 'choreography', 'fight', 'scene', 'go', 'infinitely', 'long', 'dissolve', 'shane', 'diary', 'anne', 'frank', 'dynasty', 'rise', 'fell', 'geological', 'epoch', 'come', 'go', 'liz', 'taylor', 'monty', 'clift', 'kiss', 'place', 'sun', 'comic', 'mode', 'excels', 'story', 'male', 'bonding', 'would', 'easy', 'easy', 'read', 'homoeroticism', 'many', 'people', 'howard', 'hawk', 'hatred', 'woman', 'isnt', 'sometimes', 'thing', 'portrayed', 'screen', 'dont', 'deserve', 'much', 'way', 'heuristic', 'attention', 'men', 'form', 'bond', 'work', 'together', 'way', 'woman', 'woman', 'share', 'secret', 'read', 'deborah', 'tannen', 'nobody', 'idea', 'anti', 'feminist', 'well', 'think', 'evolution', 'produce', 'human', 'history', 'nine', 'tenth', 'hominid', 'hunter', 'gatherer', 'men', 'tend', 'hunt', 'woman', 'gather', 'hunt', 'effective', 'team', 'enterprise', 'men', 'good', 'bonding', 'darwinianed', 'leave', 'men', 'lot', 'team', 'spirit', 'grant', 'fairbanks', 'maclaughlin', 'get', 'spade', 'sorry', 'ramble', 'evolution', 'im', 'anthropologist', 'occupational', 'disease', 'ever', 'tell', 'horse', 'vaitongi', 'samoa', 'slip', 'cement', 'fell', 'bathtub', 'youve', 'get', 'watch', 'hoof', 'joan', 'fontaine', 'lovely', 'really', 'get', 'know', 'later', 'year', 'wonder', 'many', 'movie', 'live', 'saratoga', 'california', 'sister', 'olivia', 'dehavilland', 'grow', 'go', 'convent', 'school', 'pretty', 'place', 'miss', 'adventurous', 'lively', 'farraginous', 'chronicle', 'british', 'empahh', 'height', 'never', 'forgive', 'famous', 'parody', 'peter', 'seller', 'movie', 'party', 'yes', 'colonel', 'get', 'know']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-37b17d48758b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NEGATIVE\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"POSITIVE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"|\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-31b839a4d468>\u001b[0m in \u001b[0;36mcolor_text\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/05-389-p38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.pyenv/versions/05-389-p38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1241\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/05-389-p38/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/05-389-p38/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/05-389-p38/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \"\"\"\n\u001b[0;32m-> 1652\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m   def interleave(self,\n",
      "\u001b[0;32m~/.pyenv/versions/05-389-p38/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   4075\u001b[0m               type(self._map_func.output_structure)))\n\u001b[1;32m   4076\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4077\u001b[0;31m     variant_tensor = gen_dataset_ops.flat_map_dataset(\n\u001b[0m\u001b[1;32m   4078\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4079\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/05-389-p38/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mflat_map_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   1777\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1780\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FlatMapDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for text in original_data[:10]:\n",
    "    pred = color_text(text)\n",
    "    print(\"NEGATIVE\" if pred[1] < 0 else \"POSITIVE\", \"|\", pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen2vec(x):\n",
    "    return model.get_layer(name='embedding_1')(model.get_layer(name=\"text_vectorization\")(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sen2vec([[x] for x in data.text.values[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 21, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples, words, embedding\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text\"].apply(sen2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"combined_sentiment_labelled_embedding\", X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IDS_Final-Copy1.ipynb',\n",
       " 'data',\n",
       " 'Proposal.md',\n",
       " 'jupyter',\n",
       " 'combined_sentiment_labelled.tsv',\n",
       " 'TOPHTO',\n",
       " 'combined_sentiment_labelled_embedding.npy',\n",
       " 'LICENSE',\n",
       " 're_first_model',\n",
       " '.ipynb_checkpoints',\n",
       " '.git',\n",
       " 'requirements.txt',\n",
       " 'first_model',\n",
       " 'README.md',\n",
       " 'Report.md',\n",
       " 'IDS_Final.ipynb']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen2vec_model = tf.keras.Sequential([\n",
    "    model.get_layer(name=\"text_vectorization\"),\n",
    "    model.get_layer(name='embedding_1'),\n",
    "    model.get_layer(name='lstm_1'),\n",
    "    model.get_layer(name='dense_2')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen2vec_model_interm = tf.keras.Sequential([\n",
    "    model.get_layer(name=\"text_vectorization\"),\n",
    "    model.get_layer(name='embedding_1'),\n",
    "    model.get_layer(name='lstm_1')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.sample(n=50).text.values\n",
    "\n",
    "tsne = TSNE()\n",
    "tsned_space_raw = tsne.fit_transform(sen2vec([[x] for x in sentences]).numpy().mean(axis=1))\n",
    "\n",
    "tsned_space_proc = tsne.fit_transform(sen2vec_model.predict(sentences))\n",
    "\n",
    "tsned_space_intermediate = tsne.fit_transform(sen2vec_model_interm.predict(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "05-389-p38",
   "language": "python",
   "name": "05-389-p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
