{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from highlight_text import ax_text, fig_text\n",
    "\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./combined_sentiment_labelled.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set([x for l in data.text.apply(lambda x: x.split(\" \")).values for x in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/text/text_classification_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load('imdb_reviews',\n",
    "                    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, label in train_dataset.take(1):\n",
    "#   print('text: ', example.numpy())\n",
    "#   print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary())+2,\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/GPU:0'):\n",
    "#     model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#                   optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#                   metrics=['accuracy'])\n",
    "#     history = model.fit(train_dataset, epochs=10,\n",
    "#                         validation_data=test_dataset, \n",
    "#                         validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('first_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x266b035d080>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('first_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    GREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.text[7]\n",
    "\n",
    "\n",
    "def color_text(text, model=model):\n",
    "    tokens = text.split(\" \")\n",
    "    probs = [0]\n",
    "    for k in range(0,len(tokens)):\n",
    "        probs.append(model.predict(np.array([\" \".join(tokens[:k+1])]))[0][0])\n",
    "    pred = probs[-1]\n",
    "    probs = np.diff(probs)\n",
    "    colors = [bcolors.ENDC if abs(p / max(np.abs(probs))) < 0.1 \n",
    "                  else (bcolors.RED if p < 0 else bcolors.GREEN) \n",
    "              for p in probs]\n",
    "    ends = [bcolors.ENDC] * len(probs)\n",
    "    return \" \".join([c+t+e for c,t,e in zip(colors, tokens, ends)]), pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/287871/how-to-print-colored-text-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE | \u001b[0mSo\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mis\u001b[0m \u001b[91mno\u001b[0m \u001b[0mway\u001b[0m \u001b[0mfor\u001b[0m \u001b[0mme\u001b[0m \u001b[0mto\u001b[0m \u001b[0mplug\u001b[0m \u001b[92mit\u001b[0m \u001b[0min\u001b[0m \u001b[91mhere\u001b[0m \u001b[0min\u001b[0m \u001b[0mthe\u001b[0m \u001b[92mUS\u001b[0m \u001b[91munless\u001b[0m \u001b[0mI\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mby\u001b[0m \u001b[0ma\u001b[0m \u001b[0mconverter.\u001b[0m\n",
      "POSITIVE | \u001b[92mGood\u001b[0m \u001b[0mcase,\u001b[0m \u001b[92mExcellent\u001b[0m \u001b[0mvalue.\u001b[0m\n",
      "POSITIVE | \u001b[92mGreat\u001b[0m \u001b[0mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mjawbone.\u001b[0m\n",
      "POSITIVE | \u001b[91mTied\u001b[0m \u001b[91mto\u001b[0m \u001b[0mcharger\u001b[0m \u001b[0mfor\u001b[0m \u001b[0mconversations\u001b[0m \u001b[0mlasting\u001b[0m \u001b[92mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0m45\u001b[0m \u001b[0mminutes.MAJOR\u001b[0m \u001b[92mPROBLEMS!!\u001b[0m\n",
      "POSITIVE | \u001b[0mThe\u001b[0m \u001b[0mmic\u001b[0m \u001b[0mis\u001b[0m \u001b[92mgreat.\u001b[0m\n",
      "NEGATIVE | \u001b[0mI\u001b[0m \u001b[91mhave\u001b[0m \u001b[91mto\u001b[0m \u001b[0mjiggle\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mplug\u001b[0m \u001b[91mto\u001b[0m \u001b[92mget\u001b[0m \u001b[92mit\u001b[0m \u001b[0mto\u001b[0m \u001b[91mline\u001b[0m \u001b[0mup\u001b[0m \u001b[92mright\u001b[0m \u001b[0mto\u001b[0m \u001b[92mget\u001b[0m \u001b[91mdecent\u001b[0m \u001b[0mvolume.\u001b[0m\n",
      "POSITIVE | \u001b[91mIf\u001b[0m \u001b[92myou\u001b[0m \u001b[0mhave\u001b[0m \u001b[92mseveral\u001b[0m \u001b[0mdozen\u001b[0m \u001b[0mor\u001b[0m \u001b[92mseveral\u001b[0m \u001b[0mhundred\u001b[0m \u001b[0mcontacts,\u001b[0m \u001b[91mthen\u001b[0m \u001b[91mimagine\u001b[0m \u001b[0mthe\u001b[0m \u001b[92mfun\u001b[0m \u001b[0mof\u001b[0m \u001b[0msending\u001b[0m \u001b[92meach\u001b[0m \u001b[0mof\u001b[0m \u001b[92mthem\u001b[0m \u001b[0mone\u001b[0m \u001b[0mby\u001b[0m \u001b[0mone.\u001b[0m\n",
      "NEGATIVE | \u001b[91mIf\u001b[0m \u001b[92myou\u001b[0m \u001b[91mare\u001b[0m \u001b[0mRazr\u001b[0m \u001b[0mowner...you\u001b[0m \u001b[92mmust\u001b[0m \u001b[91mhave\u001b[0m \u001b[91mthis!\u001b[0m\n",
      "NEGATIVE | \u001b[0mNeedless\u001b[0m \u001b[0mto\u001b[0m \u001b[0msay,\u001b[0m \u001b[0mI\u001b[0m \u001b[0mwasted\u001b[0m \u001b[92mmy\u001b[0m \u001b[91mmoney.\u001b[0m\n",
      "NEGATIVE | \u001b[0mWhat\u001b[0m \u001b[0ma\u001b[0m \u001b[91mwaste\u001b[0m \u001b[0mof\u001b[0m \u001b[91mmoney\u001b[0m \u001b[0mand\u001b[0m \u001b[0mtime!.\u001b[0m\n",
      "POSITIVE | \u001b[92mAnd\u001b[0m \u001b[0mthe\u001b[0m \u001b[91msound\u001b[0m \u001b[91mquality\u001b[0m \u001b[0mis\u001b[0m \u001b[92mgreat.\u001b[0m\n",
      "NEGATIVE | \u001b[0mHe\u001b[0m \u001b[91mwas\u001b[0m \u001b[92mvery\u001b[0m \u001b[0mimpressed\u001b[0m \u001b[92mwhen\u001b[0m \u001b[91mgoing\u001b[0m \u001b[91mfrom\u001b[0m \u001b[92mthe\u001b[0m \u001b[91moriginal\u001b[0m \u001b[0mbattery\u001b[0m \u001b[0mto\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mextended\u001b[0m \u001b[0mbattery.\u001b[0m\n",
      "NEGATIVE | \u001b[91mIf\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mtwo\u001b[0m \u001b[91mwere\u001b[0m \u001b[0mseperated\u001b[0m \u001b[0mby\u001b[0m \u001b[92ma\u001b[0m \u001b[0mmere\u001b[0m \u001b[92m5+\u001b[0m \u001b[0mft\u001b[0m \u001b[92mI\u001b[0m \u001b[91mstarted\u001b[0m \u001b[91mto\u001b[0m \u001b[0mnotice\u001b[0m \u001b[0mexcessive\u001b[0m \u001b[0mstatic\u001b[0m \u001b[92mand\u001b[0m \u001b[0mgarbled\u001b[0m \u001b[91msound\u001b[0m \u001b[91mfrom\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mheadset.\u001b[0m\n",
      "POSITIVE | \u001b[92mVery\u001b[0m \u001b[92mgood\u001b[0m \u001b[91mquality\u001b[0m \u001b[92mthough\u001b[0m\n",
      "POSITIVE | \u001b[0mThe\u001b[0m \u001b[0mdesign\u001b[0m \u001b[92mis\u001b[0m \u001b[92mvery\u001b[0m \u001b[0modd,\u001b[0m \u001b[0mas\u001b[0m \u001b[92mthe\u001b[0m \u001b[0mear\u001b[0m \u001b[0m\"clip\"\u001b[0m \u001b[92mis\u001b[0m \u001b[91mnot\u001b[0m \u001b[92mvery\u001b[0m \u001b[0mcomfortable\u001b[0m \u001b[92mat\u001b[0m \u001b[0mall.\u001b[0m\n",
      "POSITIVE | \u001b[92mHighly\u001b[0m \u001b[92mrecommend\u001b[0m \u001b[0mfor\u001b[0m \u001b[91many\u001b[0m \u001b[0mone\u001b[0m \u001b[0mwho\u001b[0m \u001b[0mhas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mblue\u001b[0m \u001b[0mtooth\u001b[0m \u001b[0mphone.\u001b[0m\n",
      "POSITIVE | \u001b[0mI\u001b[0m \u001b[0madvise\u001b[0m \u001b[92mEVERYONE\u001b[0m \u001b[91mDO\u001b[0m \u001b[91mNOT\u001b[0m \u001b[0mBE\u001b[0m \u001b[0mFOOLED!\u001b[0m\n",
      "NEGATIVE | \u001b[0mSo\u001b[0m \u001b[91mFar\u001b[0m \u001b[0mSo\u001b[0m \u001b[92mGood!.\u001b[0m\n",
      "POSITIVE | \u001b[92mWorks\u001b[0m \u001b[92mgreat!.\u001b[0m\n",
      "POSITIVE | \u001b[92mIt\u001b[0m \u001b[0mclicks\u001b[0m \u001b[0minto\u001b[0m \u001b[0mplace\u001b[0m \u001b[0min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mway\u001b[0m \u001b[0mthat\u001b[0m \u001b[92mmakes\u001b[0m \u001b[92myou\u001b[0m \u001b[91mwonder\u001b[0m \u001b[0mhow\u001b[0m \u001b[91mlong\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mmechanism\u001b[0m \u001b[91mwould\u001b[0m \u001b[92mlast.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for text in data.text[:20]:\n",
    "    pred = color_text(text)\n",
    "    print(\"NEGATIVE\" if pred[1] < 0 else \"POSITIVE\", \"|\", pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen2vec(x):\n",
    "    return model.get_layer(name='embedding')(model.get_layer(name=\"text_vectorization\")(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sen2vec([[x] for x in data.text.values[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 21, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples, words, embedding\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen2vec_model = tf.keras.Sequential([\n",
    "    model.get_layer(name=\"text_vectorization\"),\n",
    "    model.get_layer(name='embedding'),\n",
    "    model.get_layer(name='lstm'),\n",
    "    model.get_layer(name='dense')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen2vec_model_interm = tf.keras.Sequential([\n",
    "    model.get_layer(name=\"text_vectorization\"),\n",
    "    model.get_layer(name='embedding'),\n",
    "    model.get_layer(name='lstm')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.sample(n=50).text.values\n",
    "\n",
    "tsne = TSNE()\n",
    "tsned_space_raw = tsne.fit_transform(sen2vec([[x] for x in sentences]).numpy().mean(axis=1))\n",
    "\n",
    "tsned_space_proc = tsne.fit_transform(sen2vec_model.predict(sentences))\n",
    "\n",
    "tsned_space_intermediate = tsne.fit_transform(sen2vec_model_interm.predict(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_data = pd.DataFrame({'x_raw': tsned_space_raw[:,0], \n",
    "                               'y_raw': tsned_space_raw[:,1],\n",
    "                               'x_interm': tsned_space_intermediate[:,0], \n",
    "                               'y_interm': tsned_space_intermediate[:,1],\n",
    "                               'x_proc': tsned_space_proc[:,0], \n",
    "                               'y_proc': tsned_space_proc[:,1],\n",
    "                               'sentence': sentences, \n",
    "                               'prob': model.predict(sentences).reshape(-1).round(2).astype(str),\n",
    "                               'pred': ['Positive' if x else 'Negative' \n",
    "                                        for x in (model.predict(sentences).reshape(-1) > 0)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_raw = alt.selection_interval(empty='none', encodings=['x', 'y'])\n",
    "selector_proc = alt.selection_interval(empty='none', encodings=['x', 'y'])\n",
    "selector_interm = alt.selection_interval(empty='none', encodings=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tsned = alt.Chart(tsne_plot_data).mark_circle(size=200).encode(\n",
    "    x = 'x_raw',\n",
    "    y = 'y_raw',\n",
    "    tooltip =[alt.Tooltip('sentence'), alt.Tooltip('prob')],\n",
    "    color = alt.Color('pred', scale=alt.Scale(domain=['Negative', 'Positive'], \n",
    "                                              range=['red', 'green'])),\n",
    "    opacity=alt.Opacity('prob', legend=None, scale=alt.Scale(type='log'))\n",
    ").properties(\n",
    "    title='Raw sentences'\n",
    ").add_selection(\n",
    "    selector_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_tsned = alt.Chart(tsne_plot_data).mark_circle(size=200).encode(\n",
    "    x = 'x_interm',\n",
    "    y = 'y_interm',\n",
    "    tooltip =[alt.Tooltip('sentence'), alt.Tooltip('prob')],\n",
    "    color = alt.Color('pred', scale=alt.Scale(domain=['Negative', 'Positive'], \n",
    "                                              range=['red', 'green'])),\n",
    "    opacity=alt.Opacity('prob', legend=None)\n",
    ").properties(\n",
    "    title='Intermediate state'\n",
    ").add_selection(\n",
    "    selector_interm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tsned = alt.Chart(tsne_plot_data).mark_circle(size=200).encode(\n",
    "    x = 'x_proc',\n",
    "    y = 'y_proc',\n",
    "    tooltip =[alt.Tooltip('sentence'), alt.Tooltip('prob')],\n",
    "    color = alt.Color('pred', scale=alt.Scale(domain=['Negative', 'Positive'], \n",
    "                                              range=['red', 'green'])),\n",
    "    opacity=alt.Opacity('prob', legend=None)\n",
    ").properties(\n",
    "    title='Processed sentences'\n",
    ").add_selection(\n",
    "    selector_proc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-2bb6e2ecc48b4eedb61fd8ea3190a851\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2bb6e2ecc48b4eedb61fd8ea3190a851\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2bb6e2ecc48b4eedb61fd8ea3190a851\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"circle\", \"size\": 200}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"pred\", \"scale\": {\"domain\": [\"Negative\", \"Positive\"], \"range\": [\"red\", \"green\"]}}, \"opacity\": {\"type\": \"nominal\", \"field\": \"prob\", \"legend\": null, \"scale\": {\"type\": \"log\"}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"sentence\"}, {\"type\": \"nominal\", \"field\": \"prob\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"x_raw\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_raw\"}}, \"selection\": {\"selector018\": {\"type\": \"interval\", \"empty\": \"none\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Raw sentences\"}, {\"mark\": {\"type\": \"circle\", \"size\": 200}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"pred\", \"scale\": {\"domain\": [\"Negative\", \"Positive\"], \"range\": [\"red\", \"green\"]}}, \"opacity\": {\"type\": \"nominal\", \"field\": \"prob\", \"legend\": null}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"sentence\"}, {\"type\": \"nominal\", \"field\": \"prob\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"x_interm\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_interm\"}}, \"selection\": {\"selector020\": {\"type\": \"interval\", \"empty\": \"none\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Intermediate state\"}, {\"mark\": {\"type\": \"circle\", \"size\": 200}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"pred\", \"scale\": {\"domain\": [\"Negative\", \"Positive\"], \"range\": [\"red\", \"green\"]}}, \"opacity\": {\"type\": \"nominal\", \"field\": \"prob\", \"legend\": null}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"sentence\"}, {\"type\": \"nominal\", \"field\": \"prob\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"x_proc\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_proc\"}}, \"selection\": {\"selector019\": {\"type\": \"interval\", \"empty\": \"none\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Processed sentences\"}], \"data\": {\"name\": \"data-6136212a69d69d07cf0a7f758e6c46ae\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-6136212a69d69d07cf0a7f758e6c46ae\": [{\"x_raw\": 12.985114097595215, \"y_raw\": 13.887114524841309, \"x_interm\": -14.64317512512207, \"y_interm\": 74.54073333740234, \"x_proc\": 11.507078170776367, \"y_proc\": -87.73542022705078, \"sentence\": \"I have eaten here multiple times, and each time the food was delicious.\", \"prob\": \"0.94\", \"pred\": \"Positive\"}, {\"x_raw\": -35.909183502197266, \"y_raw\": 11.156900405883789, \"x_interm\": -40.07243728637695, \"y_interm\": 47.78946304321289, \"x_proc\": -6.736952304840088, \"y_proc\": -100.48294067382812, \"sentence\": \"Great choice!\", \"prob\": \"0.84\", \"pred\": \"Positive\"}, {\"x_raw\": -20.624147415161133, \"y_raw\": -2.655895948410034, \"x_interm\": 41.54322814941406, \"y_interm\": -0.5250067114830017, \"x_proc\": 28.0283203125, \"y_proc\": 2.289766550064087, \"sentence\": \"Crust is not good.\", \"prob\": \"0.06\", \"pred\": \"Positive\"}, {\"x_raw\": 27.430103302001953, \"y_raw\": -8.657265663146973, \"x_interm\": 52.998294830322266, \"y_interm\": -70.46659851074219, \"x_proc\": 18.990217208862305, \"y_proc\": 112.43714141845703, \"sentence\": \"I mean really, how do you get so famous for your fish and chips when it's so terrible!?!\", \"prob\": \"-1.06\", \"pred\": \"Negative\"}, {\"x_raw\": -5.050445556640625, \"y_raw\": -0.8593071103096008, \"x_interm\": -5.717478275299072, \"y_interm\": -73.35448455810547, \"x_proc\": 3.0845515727996826, \"y_proc\": 75.03978729248047, \"sentence\": \"Maybe if they weren't cold they would have been somewhat edible.\", \"prob\": \"-0.71\", \"pred\": \"Negative\"}, {\"x_raw\": 6.427893161773682, \"y_raw\": 7.028484344482422, \"x_interm\": 49.779354095458984, \"y_interm\": -21.503509521484375, \"x_proc\": -22.05476188659668, \"y_proc\": 36.30108642578125, \"sentence\": \"The movie was very interesting from beginning to the end.  \", \"prob\": \"-0.07\", \"pred\": \"Negative\"}, {\"x_raw\": 19.3056640625, \"y_raw\": 20.252599716186523, \"x_interm\": -20.721399307250977, \"y_interm\": 114.58354949951172, \"x_proc\": -56.644622802734375, \"y_proc\": -117.1631851196289, \"sentence\": \"The sergeant pepper beef sandwich with auju sauce is an excellent sandwich as well.\", \"prob\": \"1.91\", \"pred\": \"Positive\"}, {\"x_raw\": 21.399517059326172, \"y_raw\": 12.024323463439941, \"x_interm\": 1.0063518285751343, \"y_interm\": -91.83602905273438, \"x_proc\": 38.740482330322266, \"y_proc\": 74.80609893798828, \"sentence\": \"First - the bathrooms at this location were dirty- Seat covers were not replenished & just plain yucky!!!\", \"prob\": \"-0.84\", \"pred\": \"Negative\"}, {\"x_raw\": -36.51240158081055, \"y_raw\": 3.085415840148926, \"x_interm\": -20.102012634277344, \"y_interm\": 22.666318893432617, \"x_proc\": -7.0522780418396, \"y_proc\": -36.96480178833008, \"sentence\": \"Works as described.\", \"prob\": \"0.58\", \"pred\": \"Positive\"}, {\"x_raw\": 17.60663604736328, \"y_raw\": 0.5985184907913208, \"x_interm\": -3.6696317195892334, \"y_interm\": 93.69478607177734, \"x_proc\": -30.743635177612305, \"y_proc\": -113.61917114257812, \"sentence\": \"The sets (especially designed to work with the camera) are amazing....stylized, beautiful and effective.  \", \"prob\": \"1.23\", \"pred\": \"Positive\"}, {\"x_raw\": 24.418624877929688, \"y_raw\": 5.862556457519531, \"x_interm\": 13.828927040100098, \"y_interm\": -44.33441162109375, \"x_proc\": -3.7178282737731934, \"y_proc\": 53.92183303833008, \"sentence\": \"however, my girl was complain that some time the phone doesn't wake up like normal phone does.\", \"prob\": \"-0.46\", \"pred\": \"Negative\"}, {\"x_raw\": -28.922788619995117, \"y_raw\": 15.792337417602539, \"x_interm\": -0.6258217692375183, \"y_interm\": 40.77256393432617, \"x_proc\": -61.34751892089844, \"y_proc\": -43.19434356689453, \"sentence\": \"dont buy it.\", \"prob\": \"0.7\", \"pred\": \"Positive\"}, {\"x_raw\": -26.53432273864746, \"y_raw\": -6.882266998291016, \"x_interm\": -21.266311645507812, \"y_interm\": -33.730125427246094, \"x_proc\": 38.658145904541016, \"y_proc\": 25.095104217529297, \"sentence\": \"And then tragedy struck.\", \"prob\": \"-0.18\", \"pred\": \"Negative\"}, {\"x_raw\": 34.3969841003418, \"y_raw\": -0.08649995923042297, \"x_interm\": 16.78790855407715, \"y_interm\": 36.76061248779297, \"x_proc\": -0.05918616056442261, \"y_proc\": -56.112693786621094, \"sentence\": \"So I had to take the battery out of the phone put it all back together and then restart it.\", \"prob\": \"0.63\", \"pred\": \"Positive\"}, {\"x_raw\": 45.75431823730469, \"y_raw\": 12.379798889160156, \"x_interm\": -49.884925842285156, \"y_interm\": 97.8494644165039, \"x_proc\": -52.27482223510742, \"y_proc\": -138.47540283203125, \"sentence\": \"If you do watch it, however, there are small consolations: The actresses playing Anne's sisters each do a wonderful job with their roles.  \", \"prob\": \"2.01\", \"pred\": \"Positive\"}, {\"x_raw\": 39.88359069824219, \"y_raw\": 5.970564365386963, \"x_interm\": -22.513084411621094, \"y_interm\": 57.88019561767578, \"x_proc\": -66.70487213134766, \"y_proc\": -69.60933685302734, \"sentence\": \"Feelings, thoughts...Gabriel's discomfort during the dance...all these intangibles leap to life and come within the viewer's grasp in Huston's portrayal.  \", \"prob\": \"0.89\", \"pred\": \"Positive\"}, {\"x_raw\": -20.57517433166504, \"y_raw\": 9.757939338684082, \"x_interm\": 26.415557861328125, \"y_interm\": -14.760695457458496, \"x_proc\": -34.007957458496094, \"y_proc\": 16.49079704284668, \"sentence\": \"Waitress was sweet and funny.\", \"prob\": \"0.08\", \"pred\": \"Positive\"}, {\"x_raw\": 1.7659564018249512, \"y_raw\": -3.674307107925415, \"x_interm\": 29.329492568969727, \"y_interm\": -58.84174728393555, \"x_proc\": 19.89409637451172, \"y_proc\": 84.94378662109375, \"sentence\": \"Furthermore, you can't even find hours of operation on the website!\", \"prob\": \"-0.71\", \"pred\": \"Negative\"}, {\"x_raw\": 36.358314514160156, \"y_raw\": -6.9609503746032715, \"x_interm\": 13.967086791992188, \"y_interm\": 55.816497802734375, \"x_proc\": -28.443161010742188, \"y_proc\": -71.14642333984375, \"sentence\": \"No one at the table thought the food was above average or worth the wait that we had for it.\", \"prob\": \"0.87\", \"pred\": \"Positive\"}, {\"x_raw\": 46.93012237548828, \"y_raw\": -11.684359550476074, \"x_interm\": 13.082161903381348, \"y_interm\": -26.054828643798828, \"x_proc\": -3.2623538970947266, \"y_proc\": 26.327932357788086, \"sentence\": \"I do not know if this was Emilio Estevez's directorial debut, but the pacing, the interplay and development of the characters as well as some clever camera work surrounding the character Estevez plays all suggest a natural eye.  \", \"prob\": \"-0.05\", \"pred\": \"Negative\"}, {\"x_raw\": 48.939247131347656, \"y_raw\": 4.019326686859131, \"x_interm\": 64.83753967285156, \"y_interm\": -101.05602264404297, \"x_proc\": 81.65507507324219, \"y_proc\": 99.61651611328125, \"sentence\": \"You can't even tell if they have any talent because they not only have pathetic lines to speak but the director gave them no action.  \", \"prob\": \"-1.87\", \"pred\": \"Negative\"}, {\"x_raw\": -34.767059326171875, \"y_raw\": -6.034158706665039, \"x_interm\": -28.361433029174805, \"y_interm\": 95.62348937988281, \"x_proc\": -73.75463104248047, \"y_proc\": -102.34305572509766, \"sentence\": \"This is an excellent film.  \", \"prob\": \"1.6\", \"pred\": \"Positive\"}, {\"x_raw\": -6.3781514167785645, \"y_raw\": -8.347476959228516, \"x_interm\": 11.361028671264648, \"y_interm\": -63.427642822265625, \"x_proc\": 20.43352699279785, \"y_proc\": 62.819393157958984, \"sentence\": \"I found this product to be waaay too big.\", \"prob\": \"-0.66\", \"pred\": \"Negative\"}, {\"x_raw\": -14.67878246307373, \"y_raw\": 3.172943592071533, \"x_interm\": -4.230257034301758, \"y_interm\": 58.91377639770508, \"x_proc\": -8.430377006530762, \"y_proc\": -76.4615707397461, \"sentence\": \"I will be back many times soon.\", \"prob\": \"0.9\", \"pred\": \"Positive\"}, {\"x_raw\": -13.107867240905762, \"y_raw\": -4.147489070892334, \"x_interm\": 17.250394821166992, \"y_interm\": -80.10791778564453, \"x_proc\": 0.09812510758638382, \"y_proc\": 98.3519058227539, \"sentence\": \"There is nothing privileged about working/eating there.\", \"prob\": \"-0.87\", \"pred\": \"Negative\"}, {\"x_raw\": 31.506471633911133, \"y_raw\": 6.245997428894043, \"x_interm\": -39.8272590637207, \"y_interm\": 26.858158111572266, \"x_proc\": -20.696619033813477, \"y_proc\": -53.21599197387695, \"sentence\": \"As much as I'd like to go back, I can't get passed the atrocious service and will never return.\", \"prob\": \"0.69\", \"pred\": \"Positive\"}, {\"x_raw\": -13.248990058898926, \"y_raw\": 9.970370292663574, \"x_interm\": 3.9149904251098633, \"y_interm\": 3.8777875900268555, \"x_proc\": 8.070266723632812, \"y_proc\": -15.826529502868652, \"sentence\": \"We won't be going back anytime soon!\", \"prob\": \"0.25\", \"pred\": \"Positive\"}, {\"x_raw\": 26.48506736755371, \"y_raw\": -0.7228958606719971, \"x_interm\": -21.324615478515625, \"y_interm\": -58.43093490600586, \"x_proc\": 38.673011779785156, \"y_proc\": 49.494606018066406, \"sentence\": \"I guess that nobody at the network that aired this dribble watched it before putting it on.  \", \"prob\": \"-0.49\", \"pred\": \"Negative\"}, {\"x_raw\": 8.04643440246582, \"y_raw\": 21.557756423950195, \"x_interm\": -40.96755599975586, \"y_interm\": 116.0605239868164, \"x_proc\": -75.74378967285156, \"y_proc\": -129.892822265625, \"sentence\": \"He also came back to check on us regularly, excellent service.\", \"prob\": \"2.22\", \"pred\": \"Positive\"}, {\"x_raw\": -10.449091911315918, \"y_raw\": 17.6570987701416, \"x_interm\": -2.7077770233154297, \"y_interm\": 23.1328182220459, \"x_proc\": -50.018062591552734, \"y_proc\": -21.933696746826172, \"sentence\": \"Service was fine and the waitress was friendly.\", \"prob\": \"0.54\", \"pred\": \"Positive\"}, {\"x_raw\": 10.600276947021484, \"y_raw\": -6.536377906799316, \"x_interm\": 22.40277862548828, \"y_interm\": -99.14978790283203, \"x_proc\": 37.0450553894043, \"y_proc\": 99.57453155517578, \"sentence\": \"As many people complained, I found this headset's microphone was very weak.\", \"prob\": \"-1.15\", \"pred\": \"Negative\"}, {\"x_raw\": 7.677550792694092, \"y_raw\": 0.43366771936416626, \"x_interm\": 32.17678451538086, \"y_interm\": -35.61564254760742, \"x_proc\": 14.56229019165039, \"y_proc\": 41.647518157958984, \"sentence\": \"I didn't think that the instructions provided were helpful to me.\", \"prob\": \"-0.28\", \"pred\": \"Negative\"}, {\"x_raw\": 28.07366180419922, \"y_raw\": 13.406453132629395, \"x_interm\": -16.550256729125977, \"y_interm\": -12.417741775512695, \"x_proc\": -14.177545547485352, \"y_proc\": 7.760608673095703, \"sentence\": \"The puppets look really cheesy , not in a good way like in the Puppet Master 80's flicks.  \", \"prob\": \"0.1\", \"pred\": \"Positive\"}, {\"x_raw\": 13.953092575073242, \"y_raw\": 6.839959621429443, \"x_interm\": 13.767587661743164, \"y_interm\": 18.310012817382812, \"x_proc\": -11.51720905303955, \"y_proc\": -14.138605117797852, \"sentence\": \"Now the pizza itself was good the peanut sauce was very tasty.\", \"prob\": \"0.35\", \"pred\": \"Positive\"}, {\"x_raw\": 3.6026926040649414, \"y_raw\": 14.364409446716309, \"x_interm\": 2.954206705093384, \"y_interm\": -12.297607421875, \"x_proc\": 5.619827747344971, \"y_proc\": 5.10944128036499, \"sentence\": \"It'll be a regular stop on my trips to Phoenix!\", \"prob\": \"0.04\", \"pred\": \"Positive\"}, {\"x_raw\": 52.11037063598633, \"y_raw\": -5.41616678237915, \"x_interm\": 30.995983123779297, \"y_interm\": -120.0959243774414, \"x_proc\": 66.14110565185547, \"y_proc\": 119.1432113647461, \"sentence\": \"I hate writing bad reviews about films - especially those in which I really like the star - but this film is so bad I don't believe for one second that anyone could have been proud of it.  \", \"prob\": \"-1.55\", \"pred\": \"Negative\"}, {\"x_raw\": -0.9600328207015991, \"y_raw\": 20.273435592651367, \"x_interm\": -19.828168869018555, \"y_interm\": 40.65665054321289, \"x_proc\": 19.554819107055664, \"y_proc\": -65.00227355957031, \"sentence\": \"Excellently produced by one of Sci-fi's best producers Scot Vandiver !  \", \"prob\": \"0.78\", \"pred\": \"Positive\"}, {\"x_raw\": 4.044736385345459, \"y_raw\": -10.885483741760254, \"x_interm\": 50.7244758605957, \"y_interm\": -116.82952880859375, \"x_proc\": 43.67776107788086, \"y_proc\": 123.32640838623047, \"sentence\": \"I would avoid this place if you are staying in the Mirage.\", \"prob\": \"-1.49\", \"pred\": \"Negative\"}, {\"x_raw\": -5.160989761352539, \"y_raw\": 13.53597640991211, \"x_interm\": 6.953610420227051, \"y_interm\": 75.55430603027344, \"x_proc\": -26.624858856201172, \"y_proc\": -90.81153869628906, \"sentence\": \"And the beans and rice were mediocre at best.\", \"prob\": \"0.91\", \"pred\": \"Positive\"}, {\"x_raw\": -29.605972290039062, \"y_raw\": 0.4443572163581848, \"x_interm\": -12.303979873657227, \"y_interm\": 6.2388691902160645, \"x_proc\": 15.672012329101562, \"y_proc\": -36.84138488769531, \"sentence\": \"nice leather.\", \"prob\": \"0.38\", \"pred\": \"Positive\"}, {\"x_raw\": -6.9784746170043945, \"y_raw\": 6.35951042175293, \"x_interm\": 27.46484375, \"y_interm\": 70.01055145263672, \"x_proc\": -46.150390625, \"y_proc\": -62.97014236450195, \"sentence\": \"The best electronics of the available FM Transmitters.\", \"prob\": \"0.86\", \"pred\": \"Positive\"}, {\"x_raw\": -0.3062514364719391, \"y_raw\": 9.384778022766113, \"x_interm\": -36.80739212036133, \"y_interm\": 70.3890151977539, \"x_proc\": -48.016990661621094, \"y_proc\": -86.74688720703125, \"sentence\": \"O my gosh the best phone I have ever had.\", \"prob\": \"0.97\", \"pred\": \"Positive\"}, {\"x_raw\": -21.178298950195312, \"y_raw\": 17.11513328552246, \"x_interm\": 32.97016906738281, \"y_interm\": 19.79417610168457, \"x_proc\": -33.455238342285156, \"y_proc\": -7.365759372711182, \"sentence\": \"Nice design and quality.\", \"prob\": \"0.37\", \"pred\": \"Positive\"}, {\"x_raw\": 42.50493621826172, \"y_raw\": -1.2794506549835205, \"x_interm\": 36.63461685180664, \"y_interm\": -80.81978607177734, \"x_proc\": 60.98591613769531, \"y_proc\": 73.87494659423828, \"sentence\": \"This one wants to surf on the small wave of space movies in 1998 (Deep Impact and Armageddon), and this one fails everywhere.  \", \"prob\": \"-1.09\", \"pred\": \"Negative\"}, {\"x_raw\": -28.875272750854492, \"y_raw\": 8.031476974487305, \"x_interm\": -4.209786415100098, \"y_interm\": -28.94101905822754, \"x_proc\": 17.32340431213379, \"y_proc\": 21.48431968688965, \"sentence\": \"Absolutel junk.\", \"prob\": \"-0.08\", \"pred\": \"Negative\"}, {\"x_raw\": 33.98310470581055, \"y_raw\": 19.77573013305664, \"x_interm\": -2.973635196685791, \"y_interm\": -52.667945861816406, \"x_proc\": -18.002195358276367, \"y_proc\": 75.04234313964844, \"sentence\": \"The sound is clear and the people I talk to on it are amazed at the quality too.\", \"prob\": \"-0.65\", \"pred\": \"Negative\"}, {\"x_raw\": -23.174991607666016, \"y_raw\": 3.5192525386810303, \"x_interm\": 21.213010787963867, \"y_interm\": 1.6531407833099365, \"x_proc\": 30.49718475341797, \"y_proc\": -19.526296615600586, \"sentence\": \"A pretty good product.\", \"prob\": \"0.23\", \"pred\": \"Positive\"}, {\"x_raw\": 0.4481075406074524, \"y_raw\": 3.141289234161377, \"x_interm\": -31.67925262451172, \"y_interm\": 4.753418445587158, \"x_proc\": -25.576139450073242, \"y_proc\": -27.842941284179688, \"sentence\": \"I got home to see the driest damn wings ever!\", \"prob\": \"0.45\", \"pred\": \"Positive\"}, {\"x_raw\": -19.69247817993164, \"y_raw\": -11.30915355682373, \"x_interm\": 42.79124450683594, \"y_interm\": -98.79943084716797, \"x_proc\": 57.4990348815918, \"y_proc\": 97.29515838623047, \"sentence\": \"Avoid at all costs.  \", \"prob\": \"-1.32\", \"pred\": \"Negative\"}, {\"x_raw\": 36.39873123168945, \"y_raw\": 11.93359661102295, \"x_interm\": 34.73756408691406, \"y_interm\": 44.04354476928711, \"x_proc\": -38.36258316040039, \"y_proc\": -43.051429748535156, \"sentence\": \"I always order from the vegetarian menu during dinner, which has a wide array of options to choose from.\", \"prob\": \"0.61\", \"pred\": \"Positive\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_tsned | interm_tsned | sentences_tsned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
